{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e58895a-f32f-4b6f-a51b-8cee8144cee6",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b1650a11-757b-4789-b76e-e8afa69602bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import chi2_contingency\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from statistics import mean\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "import time\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34702d17-d593-4255-9374-391bca21dcfa",
   "metadata": {},
   "source": [
    "### Importing the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c72a76ab-e0bf-48e0-b401-83b78f12e118",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train_data_enriched.csv\", index_col=\"Claim Identifier\")\n",
    "data = df.copy()\n",
    "data_test = pd.read_csv(\"test_data_enriched.csv\",index_col=\"Claim Identifier\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a73431-0d2f-4a53-b31a-0e1add7deb0e",
   "metadata": {},
   "source": [
    "### Defining the types of our numerical features to input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d9214b6b-3831-49df-abc2-657c89ab3e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = ['Age at Injury', 'Average Weekly Wage', 'Birth Year', 'IME-4 Count', 'Number of Dependents',\n",
    "                \"Accident Year\",\"Accident Month\",\"Accident Day\",\"Accident DayOfWeek\",\"Assembly Date DSA\",\n",
    "                \"C-2 Date DSA\",\"C-3 Date DSA\",\"First Hearing Date DSA\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98724ed-c478-4821-8349-cfcdc578a029",
   "metadata": {},
   "source": [
    "#### Dropping variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "71ee328b-b562-4d9b-a7cf-ca38cf5d0e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping redundant variables that carry almost the same information (are extremely correlated (|0.8|))\n",
    "# We believe it was better to keep Age at Injury than birth year since it should be more related to the injury claim type (it will be tested later)\n",
    "# The same logic was applied to dropping the other two dates and two DSA variables since we believe Accident date to be more important\n",
    "data.drop(['Birth Year','Assembly Date', \"C-2 Date\",\"Assembly Date DSA\", \"First Hearing Date DSA\"], axis = 1, inplace = True)\n",
    "data_test.drop(['Birth Year','Assembly Date', \"C-2 Date\",\"Assembly Date DSA\", \"First Hearing Date DSA\"], axis = 1, inplace = True)\n",
    "\n",
    "for col in ['Birth Year',\"Assembly Date DSA\", \"First Hearing Date DSA\"]:\n",
    "    num_features.remove(col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5500e539-35ca-44d6-8ed8-14e699a3ee57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since the codes always seem to provide the same or more information than the descriptions (have more categories),\n",
    "#and the codes are consistent (always only having 1 description for code, while descriptions may have multiple codes)\n",
    "#we will drop the description columns.\n",
    "data.drop(['Industry Code Description','WCIO Cause of Injury Description','WCIO Nature of Injury Description','WCIO Part Of Body Description'], axis = 1,inplace = True)\n",
    "data_test.drop(['Industry Code Description','WCIO Cause of Injury Description','WCIO Nature of Injury Description','WCIO Part Of Body Description'], axis = 1,inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "57cbdf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing Zip Code for reason meantion in pre-processement\n",
    "data.drop(['Zip Code'], axis=1, inplace = True)\n",
    "data_test.drop(['Zip Code'], axis=1 , inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e61f5f-9e27-4f71-9647-e144c03a6de0",
   "metadata": {},
   "source": [
    "### Converting our target into labels for our model to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0c557798",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3a936478",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Label inconding our target variable \n",
    "data[\"Claim Injury Type\"] = le.fit_transform(data[\"Claim Injury Type\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc5dd21-3733-4e89-9130-96ec78304833",
   "metadata": {},
   "source": [
    "### Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c7e471ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputing missing values with a given algorithm\n",
    "def impute_missing_values(data, target_column, algorithm):\n",
    "    \n",
    "    # Separating the missing values from the non missing values\n",
    "    available_data = data[data[target_column].notna()]\n",
    "    missing_data = data[data[target_column].isna()]\n",
    "\n",
    "    # Making sure there is enough data to input \n",
    "    if len(available_data) == 0 or len(missing_data) == 0:\n",
    "        return data\n",
    "\n",
    "    # Separating the target column from the rest \n",
    "    X_available = available_data.drop(columns=[target_column])\n",
    "    y_available = available_data[target_column]\n",
    "\n",
    "    # Training the model with the available data\n",
    "    model = algorithm\n",
    "    model.fit(X_available, y_available)\n",
    "\n",
    "    # Prediting the missing values\n",
    "    X_missing = missing_data.drop(columns=[target_column])\n",
    "    predicted_values = model.predict(X_missing)\n",
    "\n",
    "    # Inputing the missing values with the predictions\n",
    "    data.loc[data[target_column].isna(), target_column] = predicted_values\n",
    "\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5875a3-e541-4949-b835-050708919f2f",
   "metadata": {},
   "source": [
    "### Defining X and y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9060e3f5-fa7b-459e-8684-74a9147cb371",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop([\"Claim Injury Type\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1d735692-3570-4403-b334-55c4c5476a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[\"Claim Injury Type\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a152e7-398a-4598-9c34-6e1bfa338170",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab1d5f5-caf7-4e19-8948-5560edb5708e",
   "metadata": {},
   "source": [
    "### RFE (repeated feature elimination) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9705ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Rfe(algorithm, num_inputing_algorithm= DecisionTreeRegressor() , cat_inputing_algorithm = DecisionTreeClassifier()):\n",
    "\n",
    "    X_train, X_val,y_train, y_val = train_test_split(X,y,\n",
    "                                                train_size = 0.75, \n",
    "                                                shuffle = True, \n",
    "                                                stratify = y)\n",
    "\n",
    "    #Filling num missing values\n",
    "    for column in num_features:\n",
    "        impute_missing_values(X_train, column, num_inputing_algorithm)\n",
    "        impute_missing_values(X_val, column, num_inputing_algorithm)\n",
    "\n",
    "    #Filling cat missing values\n",
    "    impute_missing_values(X_train, \"Alternative Dispute Resolution\", cat_inputing_algorithm)\n",
    "    impute_missing_values(X_val, \"Alternative Dispute Resolution\", cat_inputing_algorithm)\n",
    "\n",
    "    # Removing inconsistencies on the train\n",
    "    inconsistent = X_train[(X_train['Age at Injury'] > 80) | (X_train[\"Age at Injury\"] < 16)].index\n",
    "    X_train.drop(inconsistent, inplace=True)\n",
    "    y_train.drop(inconsistent, inplace=True)\n",
    "    \n",
    "    #Generating the variables where we will store our results\n",
    "    nof_list = np.arange(1, len(X_train.columns) + 1)            \n",
    "    high_score = 0\n",
    "    opt_n_features = 0\n",
    "    train_score_list = []\n",
    "    val_score_list = []\n",
    "\n",
    "    #Variable where we will store the optimum amount of features\n",
    "    best_rfe = None\n",
    "\n",
    "    model = algorithm\n",
    "\n",
    "    for n in nof_list:\n",
    "        rfe = RFE(estimator=model, n_features_to_select=n)\n",
    "    \n",
    "    # Fitting the model to rfe\n",
    "        X_train_rfe = rfe.fit_transform(X_train, y_train)\n",
    "        X_val_rfe = rfe.transform(X_val)\n",
    "    \n",
    "    # Training and predicting\n",
    "        model.fit(X_train_rfe, y_train)\n",
    "        pred_train = model.predict(X_train_rfe)\n",
    "        pred_val = model.predict(X_val_rfe)\n",
    "    \n",
    "    # Evaluating using the macro f1_score\n",
    "        train_score = f1_score(y_train, pred_train, average=\"macro\")\n",
    "        val_score = f1_score(y_val, pred_val, average=\"macro\")\n",
    "        train_score_list.append(train_score)\n",
    "        val_score_list.append(val_score)\n",
    "    \n",
    "    # Checking if this is the best combination of features so far\n",
    "        if val_score >= high_score:\n",
    "            high_score = val_score\n",
    "            opt_n_features = n\n",
    "            best_rfe = rfe  # Armazenar o RFE com o melhor número de features\n",
    "\n",
    "# Checking what amount of features and which features where the best for the model\n",
    "    selected_features = X_train.columns[best_rfe.support_].tolist()\n",
    "\n",
    "    print(\"Optimal number of features: %d\" % opt_n_features)\n",
    "    print(\"Score with %d features: %f\" % (opt_n_features, high_score))\n",
    "    print(\"Selected Features:\\n\", selected_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a935a4-ec5e-4ec6-85d4-4bde28b9bf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rfe(DecisionTreeClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf6ea91-f162-4555-9fb8-d629bd23c005",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rfe(RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3742196f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rfe(XGBClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c006d9ad-0ccf-4060-94c7-8e914b0f812c",
   "metadata": {},
   "source": [
    "### These were the variables we obtained as a result of our RFE with a random forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "392350dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = ['Accident Date', 'Age at Injury', 'Alternative Dispute Resolution', 'Attorney/Representative', 'Average Weekly Wage', 'C-3 Date', 'Carrier Name', 'Carrier Type', 'County of Injury',\n",
    "                      'COVID-19 Indicator', 'District Name', 'First Hearing Date', 'Gender', 'IME-4 Count', 'Industry Code', 'Medical Fee Region', 'WCIO Cause of Injury Code', 'WCIO Nature of Injury Code', \n",
    "                      'WCIO Part Of Body Code', 'Number of Dependents', 'Accident Year', 'Accident Month', 'Accident Day', 'Accident DayOfWeek', 'C-2 Date DSA', 'C-3 Date DSA',\n",
    "                        'Accident Date_missing', 'First Hearing Date_missing', 'C-3 Date_missing', 'Assembly Date_missing', 'C-2 Date_missing', 'Age at Injury Category',\n",
    "                        'Carrier Claim Category', 'Body Section']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b1bc02b4-1c05-4bdc-ad00-9d5513855824",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_num_features = ['Age at Injury', 'Average Weekly Wage','IME-4 Count','Number of Dependents',\n",
    "                         'Accident Year','Accident Month', 'Accident Day', 'Accident DayOfWeek',\n",
    "                         'C-2 Date DSA', 'C-3 Date DSA']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09acaaa4-7ec2-4fce-bfcb-42d3e9a09aee",
   "metadata": {},
   "source": [
    "# Decision tree models and performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "81144bdd-d672-488b-873e-d3677c178acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computes the crossvalidation scores\n",
    "def cv_scores(model, X, y, num_inputing_algorithm= XGBRegressor() , cat_inputing_algorithm = XGBClassifier()):\n",
    "    # Takes as argument the model used, the predictors and the target. Splits the data using StratifiedKFold, and\n",
    "    # trains model using X and y. Then it returns the results obtained from the stratified cross validation'''\n",
    "    \n",
    "    skf = KFold(n_splits=5)\n",
    "    \n",
    "    # Generating the lists to store our results\n",
    "    precision_scores_train = []\n",
    "    precision_scores_val = []   \n",
    "    recall_scores_train = []  \n",
    "    recall_scores_val = []\n",
    "    f1_scores_train = []    \n",
    "    f1_scores_val = []\n",
    "    index = [f'Fold {i}' for i in range(1,6)]\n",
    "    index.append(\"Average\")\n",
    "    \n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        # Dividing our data in validation and train\n",
    "        X_train, X_val = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_val = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        #Filling num missing values\n",
    "        for column in selected_num_features:\n",
    "            impute_missing_values(X_train, column, num_inputing_algorithm)\n",
    "            impute_missing_values(X_val, column, num_inputing_algorithm)\n",
    "\n",
    "        #Filling cat missing values\n",
    "        impute_missing_values(X_train, \"Alternative Dispute Resolution\", cat_inputing_algorithm)\n",
    "        impute_missing_values(X_val, \"Alternative Dispute Resolution\", cat_inputing_algorithm)\n",
    "        \n",
    "        # Removing inconsistencies on the train\n",
    "        inconsistent = X_train[(X_train['Age at Injury'] > 80) | (X_train[\"Age at Injury\"] < 16)].index\n",
    "        X_train.drop(inconsistent, inplace=True)\n",
    "        y_train.drop(inconsistent, inplace=True)\n",
    "\n",
    "\n",
    "        # Training the classification model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Making the predictions for the training and validation data\n",
    "        pred_train = model.predict(X_train)\n",
    "        pred_val = model.predict(X_val)\n",
    "        \n",
    "        # Calculating and storing the scores\n",
    "        precision_scores_train.append(precision_score(y_train, pred_train, average='macro'))\n",
    "        precision_scores_val.append(precision_score(y_val, pred_val, average='macro'))\n",
    "        recall_scores_train.append(recall_score(y_train, pred_train, average='macro'))\n",
    "        recall_scores_val.append(recall_score(y_val, pred_val, average='macro'))\n",
    "        f1_scores_train.append(f1_score(y_train, pred_train, average='macro'))\n",
    "        f1_scores_val.append(f1_score(y_val, pred_val, average='macro'))\n",
    "\n",
    "    \n",
    "    precision_scores_train.append(mean(precision_scores_train))\n",
    "    precision_scores_val.append(mean(precision_scores_val))\n",
    "    recall_scores_train.append(mean(recall_scores_train))\n",
    "    recall_scores_val.append(mean(recall_scores_val))\n",
    "    f1_scores_train.append(mean(f1_scores_train))\n",
    "    f1_scores_val.append(mean(f1_scores_val))\n",
    "\n",
    "    # Storing the results in a dataframe\n",
    "    model_results = pd.DataFrame(data={\n",
    "        'Train_precision': precision_scores_train,\n",
    "        'Test_precision': precision_scores_val,\n",
    "        'Train_recall': recall_scores_train,\n",
    "        'Test_recall': recall_scores_val,\n",
    "        'Train_f1_score': f1_scores_train,\n",
    "        'Test_f1_score': f1_scores_val,\n",
    "    }, index=index)\n",
    "    \n",
    "    return model_results\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e38375",
   "metadata": {},
   "source": [
    "after testing, the model is better with all features, so we ran with all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad7918c-b985-4fc9-8e5b-531a93d06008",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_results = cv_scores(DecisionTreeClassifier(), X[selected_features], y)\n",
    "dt_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea63847",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_results = cv_scores(DecisionTreeClassifier(), X, y)\n",
    "dt_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7e74f7-4ed4-4b2c-8595-9680cc6c0f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_results = cv_scores(RandomForestClassifier(), X, y)\n",
    "rf_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "865c2d7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train_precision</th>\n",
       "      <th>Test_precision</th>\n",
       "      <th>Train_recall</th>\n",
       "      <th>Test_recall</th>\n",
       "      <th>Train_f1_score</th>\n",
       "      <th>Test_f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Fold 1</th>\n",
       "      <td>0.796857</td>\n",
       "      <td>0.448212</td>\n",
       "      <td>0.583432</td>\n",
       "      <td>0.349683</td>\n",
       "      <td>0.612243</td>\n",
       "      <td>0.357272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold 2</th>\n",
       "      <td>0.796898</td>\n",
       "      <td>0.486657</td>\n",
       "      <td>0.583648</td>\n",
       "      <td>0.344037</td>\n",
       "      <td>0.614017</td>\n",
       "      <td>0.354671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold 3</th>\n",
       "      <td>0.796329</td>\n",
       "      <td>0.437943</td>\n",
       "      <td>0.583859</td>\n",
       "      <td>0.346069</td>\n",
       "      <td>0.614615</td>\n",
       "      <td>0.357854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold 4</th>\n",
       "      <td>0.792291</td>\n",
       "      <td>0.424510</td>\n",
       "      <td>0.574621</td>\n",
       "      <td>0.331980</td>\n",
       "      <td>0.605545</td>\n",
       "      <td>0.346707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold 5</th>\n",
       "      <td>0.785428</td>\n",
       "      <td>0.409623</td>\n",
       "      <td>0.572856</td>\n",
       "      <td>0.329006</td>\n",
       "      <td>0.602553</td>\n",
       "      <td>0.340913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average</th>\n",
       "      <td>0.793561</td>\n",
       "      <td>0.441389</td>\n",
       "      <td>0.579683</td>\n",
       "      <td>0.340155</td>\n",
       "      <td>0.609795</td>\n",
       "      <td>0.351483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Train_precision  Test_precision  Train_recall  Test_recall  \\\n",
       "Fold 1          0.796857        0.448212      0.583432     0.349683   \n",
       "Fold 2          0.796898        0.486657      0.583648     0.344037   \n",
       "Fold 3          0.796329        0.437943      0.583859     0.346069   \n",
       "Fold 4          0.792291        0.424510      0.574621     0.331980   \n",
       "Fold 5          0.785428        0.409623      0.572856     0.329006   \n",
       "Average         0.793561        0.441389      0.579683     0.340155   \n",
       "\n",
       "         Train_f1_score  Test_f1_score  \n",
       "Fold 1         0.612243       0.357272  \n",
       "Fold 2         0.614017       0.354671  \n",
       "Fold 3         0.614615       0.357854  \n",
       "Fold 4         0.605545       0.346707  \n",
       "Fold 5         0.602553       0.340913  \n",
       "Average        0.609795       0.351483  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_results = cv_scores(XGBClassifier(), X[selected_features], y)\n",
    "xgb_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335ba6b1-e9aa-4b7c-b91a-58a18ff24c67",
   "metadata": {},
   "source": [
    "# Making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bb09822b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_prediction(model, X, y , test, num_inputing_algorithm= XGBRegressor() , cat_inputing_algorithm = XGBClassifier()):\n",
    "\n",
    "    X_train, X_val,y_train, y_val = train_test_split(X,y,\n",
    "                                                train_size = 0.8, \n",
    "                                                shuffle = True, \n",
    "                                                stratify = y)\n",
    "\n",
    "    # Missing value inputation\n",
    "    #Filling num missing values\n",
    "    for column in selected_num_features:\n",
    "        impute_missing_values(X_train, column, num_inputing_algorithm)\n",
    "        impute_missing_values(X_val, column, num_inputing_algorithm)\n",
    "        impute_missing_values(test, column, num_inputing_algorithm)\n",
    "\n",
    "    #Filling cat missing values\n",
    "    impute_missing_values(X_train, \"Alternative Dispute Resolution\", cat_inputing_algorithm)\n",
    "    impute_missing_values(X_val, \"Alternative Dispute Resolution\", cat_inputing_algorithm)\n",
    "    impute_missing_values(test, \"Alternative Dispute Resolution\", cat_inputing_algorithm)\n",
    "\n",
    "    # Removing inconsistencies on the train\n",
    "    inconsistent = X_train[(X_train['Age at Injury'] > 80) | (X_train[\"Age at Injury\"] < 16)].index\n",
    "    X_train.drop(inconsistent, inplace=True)\n",
    "    y_train.drop(inconsistent, inplace=True)\n",
    "    \n",
    "    # Fitting the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Veryfing if the model is performing as expected\n",
    "    pred_val = model.predict(X_val)\n",
    "    print(f1_score(y_val, pred_val, average='macro'))\n",
    "\n",
    "    # Using the model to make prediction on the test dataset\n",
    "    pred_test = model.predict(test)\n",
    "\n",
    "    # Inversing the encoding of our target variable \n",
    "    pred_test = le.inverse_transform(pred_test)\n",
    "\n",
    "    # Making a dataframe with the indexes of data_test and predictions converted back to strings\n",
    "    submission_df = pd.DataFrame({\n",
    "        \"Claim Injury Type\": pred_test\n",
    "    }, index=data_test.index)\n",
    "    \n",
    "    return submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "00633eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.370954220930935\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Claim Injury Type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Claim Identifier</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6165911</th>\n",
       "      <td>2. NON-COMP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6166141</th>\n",
       "      <td>2. NON-COMP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6165907</th>\n",
       "      <td>2. NON-COMP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6166047</th>\n",
       "      <td>2. NON-COMP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6166102</th>\n",
       "      <td>2. NON-COMP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6553137</th>\n",
       "      <td>2. NON-COMP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6553119</th>\n",
       "      <td>1. CANCELLED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6553542</th>\n",
       "      <td>1. CANCELLED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6553455</th>\n",
       "      <td>2. NON-COMP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6553594</th>\n",
       "      <td>1. CANCELLED</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>387975 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Claim Injury Type\n",
       "Claim Identifier                  \n",
       "6165911                2. NON-COMP\n",
       "6166141                2. NON-COMP\n",
       "6165907                2. NON-COMP\n",
       "6166047                2. NON-COMP\n",
       "6166102                2. NON-COMP\n",
       "...                            ...\n",
       "6553137                2. NON-COMP\n",
       "6553119               1. CANCELLED\n",
       "6553542               1. CANCELLED\n",
       "6553455                2. NON-COMP\n",
       "6553594               1. CANCELLED\n",
       "\n",
       "[387975 rows x 1 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = test_prediction(XGBClassifier(),X[selected_features],y,data_test)\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3b833b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"Submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a814dd52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Claim Injury Type    6\n",
       "dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.nunique()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
