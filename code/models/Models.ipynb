{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "039090e4-5406-4b1c-b3c9-5b663cc2872e",
   "metadata": {},
   "source": [
    "Models Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d29f30c5-6ec1-4339-a2af-a73bd36f91c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#model imports\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier,XGBRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "#metrics\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "from statistics import mean\n",
    "\n",
    "#useful functions\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import RFE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34803428-b671-4537-b669-66a6fad30c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define an instance of the models\n",
    "#We are using the best \n",
    "DT = DecisionTreeClassifier()\n",
    "RF = RandomForestClassifier(verbose = 1, n_jobs=-1)\n",
    "XGB = XGBClassifier()\n",
    "KNN = KNeighborsClassifier(n_neighbors = 50)\n",
    "MLP = MLPClassifier(activation='relu',\n",
    "    solver='sgd',learning_rate='invscaling',\n",
    "    learning_rate_init=0.001,\n",
    "    batch_size=100,verbose = True)\n",
    "\n",
    "#Creating an instance of our encoder for the target\n",
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27ac0de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gonca\\AppData\\Local\\Temp\\ipykernel_8476\\1043285265.py:2: DtypeWarning: Columns (28) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data= pd.read_csv(\"train_data_enriched.csv\", index_col=\"Claim Identifier\")\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "data= pd.read_csv(\"train_data_enriched.csv\", index_col=\"Claim Identifier\")\n",
    "data_test = pd.read_csv(\"test_data_enriched.csv\",index_col=\"Claim Identifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41080786",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_missing_values(X_train, X_val, target_column, algorithm,validation = True):\n",
    "\n",
    "    # Separating the missing values from the non missing values\n",
    "    available_data = X_train[X_train[target_column].notna()]\n",
    "    missing_X_train = X_train[X_train[target_column].isna()]\n",
    "    missing_X_val = X_val[X_val[target_column].isna()]\n",
    "\n",
    "    # Making sure if there is enough data for inputing, returning it if not\n",
    "    if len(missing_X_train) == 0:\n",
    "        print(f\"no missing values to input on {target_column}\")\n",
    "        return X_train, X_val\n",
    "\n",
    "    # Separating the target column from the rest\n",
    "    X_available = available_data.drop(columns=[target_column])\n",
    "    y_available = available_data[target_column]\n",
    "\n",
    "    # Making sure our columns are consistent\n",
    "    X_available = X_available.select_dtypes(include=[\"number\"])\n",
    "    missing_X_train = missing_X_train.select_dtypes(include=[\"number\"])\n",
    "    missing_X_val = missing_X_val.select_dtypes(include=[\"number\"])\n",
    "\n",
    "    common_columns = X_available.columns.intersection(missing_X_train.columns).intersection(missing_X_val.columns)\n",
    "    X_available = X_available[common_columns]\n",
    "    missing_X_train = missing_X_train[common_columns]\n",
    "    missing_X_val = missing_X_val[common_columns]\n",
    "\n",
    "    # Making sure there is any column after keeping the common columns\n",
    "    if X_available.shape[1] == 0:\n",
    "        print(f\"Without any column to input in {target_column}\")\n",
    "        return X_train, X_val\n",
    "\n",
    "    # Training the model with the available data\n",
    "    model = algorithm\n",
    "    model.fit(X_available, y_available)\n",
    "\n",
    "    # Prediting the missing values\n",
    "    predicted_train = model.predict(missing_X_train)\n",
    "    if validation:\n",
    "        predicted_val = model.predict(missing_X_val)\n",
    "\n",
    "    # Filling the training and validation with predictions. The latter is only filled if the argument is true\n",
    "    X_train = X_train.copy()\n",
    "    X_train.loc[X_train[target_column].isna(), target_column] = predicted_train\n",
    "\n",
    "    if validation:\n",
    "        X_val = X_val.copy()\n",
    "        X_val.loc[X_val[target_column].isna(), target_column] = predicted_val\n",
    "\n",
    "    return X_train, X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5e1910c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def check_missing_values(data, step_name):\\n    print(f\"\\n{step_name}: Valores ausentes restantes:\")\\n    print(data.isnull().sum()[data.isnull().sum() > 0])'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This helper fuction was used for finding problems with later functions\n",
    "'''def check_missing_values(data, step_name):\n",
    "    print(f\"\\n{step_name}: Valores ausentes restantes:\")\n",
    "    print(data.isnull().sum()[data.isnull().sum() > 0])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f20a4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_outliers(data, column):\n",
    "    # Handles outliers in a numerical column by replacing values outside the interquartile range (IQR) with missing values\n",
    "\n",
    "    # Makes sure we only treat outliers in columns that have any data\n",
    "    if data[column].notnull().sum() > 0: \n",
    "\n",
    "        # Calculating inter quantile range limits\n",
    "        Q1 = data[column].quantile(0.25)\n",
    "        Q3 = data[column].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "        # Changing the ouliers to missing values\n",
    "        data[column] = np.where(data[column] < lower_bound, np.nan, data[column])\n",
    "        data[column] = np.where(data[column] > upper_bound, np.nan, data[column])\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9e310a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_numerical(column, X_train, X_val, scaler):\n",
    "    \n",
    "    # Make sure the column is numerical\n",
    "    if not pd.api.types.is_numeric_dtype(X_train[column]):\n",
    "        print(f\"Columm '{column}' is not numerical and will be ignored\")\n",
    "        return\n",
    "\n",
    "    # Scaling the data\n",
    "    try:\n",
    "        X_train[column] = scaler.fit_transform(X_train[[column]])\n",
    "        X_val[column] = scaler.transform(X_val[[column]])\n",
    "    except ValueError as e:\n",
    "        print(f\"Mistake scaling the column '{column}': {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92397747",
   "metadata": {},
   "outputs": [],
   "source": [
    "def  claim_carrier_categories(X_train, X_val):\n",
    "    \n",
    "    # Define a function to categorize each carrier based on its claim count\n",
    "    count = X_train['Carrier Name'].value_counts()\n",
    "    def categorize_claims(count):\n",
    "        if count >= 40000:\n",
    "            return 2\n",
    "        elif 4000 <= count < 40000:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    # Apply the categorization to create a mapping dictionary\n",
    "    carrier_category_map = count.apply(categorize_claims)\n",
    "\n",
    "    # Map the `Carrier Name` to the new `Carrier Claim Category`\n",
    "    X_train['Carrier Claim Category'] = X_train['Carrier Name'].map(carrier_category_map)\n",
    "    X_val['Carrier Claim Category'] = X_val['Carrier Name'].map(carrier_category_map)\n",
    "\n",
    "    return X_train.drop([\"Carrier Name\"], axis = 1, inplace = True) , X_val.drop([\"Carrier Name\"], axis = 1, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db2cfcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical encoder function\n",
    "def categorical_prop_encode(X_train, X_val, feature):\n",
    "    proportion = X_train[feature].value_counts(normalize = True)  # Get the porportion of each category\n",
    "    X_train[feature] = X_train[feature].map(proportion)  # Map the porportions in the column\n",
    "    X_val[feature] = X_val[feature].map(proportion) # Do the same for the validation subset\n",
    "    X_val[feature] = X_val[feature].fillna(0)  # Handle categories in X_val not seen in X_train with 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4efb3e3-69d9-4968-a39c-9f2cd20c4ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Rfe(algorithm,X_train,y_train,X_val,y_val):\n",
    "\n",
    "    #Generating the variables where we will store our results\n",
    "    nof_list = np.arange(1, len(X_train.columns) + 1)            \n",
    "    high_score = 0\n",
    "    opt_n_features = 0\n",
    "    train_score_list = []\n",
    "    val_score_list = []\n",
    "\n",
    "    #Variable where we will store the optimum amount of features\n",
    "    best_rfe = None\n",
    "\n",
    "    model = algorithm\n",
    "\n",
    "    for n in nof_list:\n",
    "        rfe = RFE(estimator=model, n_features_to_select=n)\n",
    "    \n",
    "    # Fitting the model to rfe\n",
    "        X_train_rfe = rfe.fit_transform(X_train, y_train)\n",
    "        X_val_rfe = rfe.transform(X_val)\n",
    "    \n",
    "    # Training and predicting\n",
    "        model.fit(X_train_rfe, y_train)\n",
    "        pred_train = model.predict(X_train_rfe)\n",
    "        pred_val = model.predict(X_val_rfe)\n",
    "    \n",
    "    # Evaluating using the macro f1_score\n",
    "        train_score = f1_score(y_train, pred_train, average=\"macro\")\n",
    "        val_score = f1_score(y_val, pred_val, average=\"macro\")\n",
    "        train_score_list.append(train_score)\n",
    "        val_score_list.append(val_score)\n",
    "    \n",
    "    # Checking if this is the best combination of features so far\n",
    "        if val_score >= high_score:\n",
    "            high_score = val_score\n",
    "            opt_n_features = n\n",
    "            best_rfe = rfe  # Storing the rfe with the best number of features\n",
    "\n",
    "# Checking what amount of features and which features where the best for the model\n",
    "    selected_features = X_train.columns[best_rfe.support_].tolist()\n",
    "\n",
    "    print(\"Optimal number of features: %d\" % opt_n_features)\n",
    "    print(\"Score with %d features: %f\" % (opt_n_features, high_score))\n",
    "    print(\"Selected Features:\\n\", selected_features)\n",
    "\n",
    "    return selected_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc04b3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_scores(X, y, num_features, cat_features, num_imputing_algorithm=XGBRegressor(), cat_imputing_algorithm=XGBClassifier(), scaling_outlier= False, scaler=MinMaxScaler(), rfe = False):\n",
    "    \"\"\"\n",
    "    Takes as argument the predictors and the target, the models used for imputing numerical and categorical \n",
    "    features, if any scaling and outlier removal should be performed,what scaling method should be used and if feature selection with rfe should be used.\n",
    "    Then it returns the results obtained from the stratified cross-validation for the given models.\n",
    "    \"\"\"\n",
    "    skf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "    # Generating the lists to store our results\n",
    "    precision_scores_train = [[],[],[],[],[]]\n",
    "    precision_scores_val = [[],[],[],[],[]]  \n",
    "    recall_scores_train = [[],[],[],[],[]]\n",
    "    recall_scores_val = [[],[],[],[],[]]\n",
    "    f1_scores_train =  [[],[],[],[],[]]\n",
    "    f1_scores_val =  [[],[],[],[],[]]\n",
    "\n",
    "    precision_scores_train_mean = []\n",
    "    precision_scores_val_mean = [] \n",
    "    recall_scores_train_mean = []\n",
    "    recall_scores_val_mean = []\n",
    "    f1_scores_train_mean =  []\n",
    "    f1_scores_val_mean =  []\n",
    "    \n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        # Dividing our data in validation and train\n",
    "        X_train, X_val = X.iloc[train_index].copy(), X.iloc[test_index].copy()\n",
    "        y_train, y_val = y.iloc[train_index].copy(), y.iloc[test_index].copy()\n",
    "\n",
    "        # Filling missing values\n",
    "        for column in num_features:\n",
    "            X_train, X_val = impute_missing_values(X_train,X_val, column, num_imputing_algorithm)\n",
    "        \n",
    "        # Removing inconsistencies on the train\n",
    "        inconsistent = X_train[(X_train['Age at Injury'] > 80) | (X_train[\"Age at Injury\"] < 16)].index\n",
    "        X_train = X_train.loc[~X_train.index.isin(inconsistent)]\n",
    "        y_train = y_train.loc[~y_train.index.isin(inconsistent)]\n",
    "\n",
    "        # Performing scaling and outlier treatment dependent on the boolean\n",
    "        if scaling_outlier:\n",
    "            for column in num_features:\n",
    "                handle_outliers(X_train, column)\n",
    "                X_train, X_val = impute_missing_values(X_train,X_val, column, num_imputing_algorithm,validation= False)\n",
    "\n",
    "            for column in num_features:\n",
    "                scale_numerical(column, X_train, X_val, scaler)\n",
    "                \n",
    "        # Creating an ordinal variable\n",
    "        claim_carrier_categories(X_train, X_val)\n",
    "\n",
    "        #Filling missing values in the ordinal variable that might appear on X_val\n",
    "        X_val, X_train = impute_missing_values(X_val,X_train, \"Carrier Claim Category\", cat_imputing_algorithm, validation=False)\n",
    "\n",
    "        # Categorical Prop Encoding\n",
    "        for cat_feature in cat_features:\n",
    "            categorical_prop_encode(X_train, X_val, cat_feature)\n",
    "            if scaling_outlier:\n",
    "                scale_numerical(\"Carrier Claim Category\", X_train, X_val, scaler)\n",
    "\n",
    "        # Selecting features with Rfe\n",
    "        if rfe:\n",
    "            Selected_features = Rfe(XGBClassifier(), X_train, y_train, X_val, y_val)\n",
    "            X_train = X_train[Selected_features]\n",
    "            X_val = X_val[Selected_features]\n",
    "\n",
    "        # Training the classification models\n",
    "        DT.fit(X_train, y_train)\n",
    "        print(\"Done DT\")\n",
    "        RF.fit(X_train, y_train)\n",
    "        print(\"Done RF\")\n",
    "        XGB.fit(X_train, y_train)\n",
    "        print(\"Done XGB\")\n",
    "        KNN.fit(X_train, y_train)\n",
    "        print(\"Done KNN\")\n",
    "        MLP.fit(X_train, y_train)\n",
    "        print(\"Done MLP\")\n",
    "\n",
    "        # Making the predictions for the training and validation data\n",
    "        pred_train_DT = DT.predict(X_train)\n",
    "        pred_train_RF = RF.predict(X_train)\n",
    "        pred_train_XGB = XGB.predict(X_train)\n",
    "        pred_train_KNN = KNN.predict(X_train)\n",
    "        pred_train_MLP = MLP.predict(X_train)\n",
    "        print(\"Done training predictions\")\n",
    "        \n",
    "        pred_val_DT = DT.predict(X_val)\n",
    "        pred_val_RF = RF.predict(X_val)\n",
    "        pred_val_XGB = XGB.predict(X_val)\n",
    "        pred_val_KNN = KNN.predict(X_val)\n",
    "        pred_val_MLP = MLP.predict(X_val)\n",
    "        print(\"Done validation predictions\")\n",
    "\n",
    "        # Calculating and storing the scores\n",
    "        i = 0\n",
    "        for predictions in [pred_train_DT,pred_train_RF,pred_train_XGB,pred_train_KNN,pred_train_MLP]:\n",
    "            precision_scores_train[i].append(precision_score(y_train, predictions, average='macro'))\n",
    "            recall_scores_train[i].append(recall_score(y_train, predictions, average='macro'))\n",
    "            f1_scores_train[i].append(f1_score(y_train, predictions, average='macro'))\n",
    "            i+=1\n",
    "        j=0\n",
    "        for predictions in [pred_val_DT,pred_val_RF,pred_val_XGB,pred_val_KNN,pred_val_MLP]:\n",
    "            precision_scores_val[j].append(precision_score(y_val, predictions, average='macro'))\n",
    "            recall_scores_val[j].append(recall_score(y_val, predictions, average='macro'))\n",
    "            f1_scores_val[j].append(f1_score(y_val, predictions, average='macro'))\n",
    "            j+=1\n",
    "\n",
    "        # Check the confusion matrixes of our predictions\n",
    "        print(confusion_matrix(y_val, pred_val_DT))\n",
    "        print(confusion_matrix(y_val, pred_val_RF))\n",
    "        print(confusion_matrix(y_val, pred_val_XGB))\n",
    "        print(confusion_matrix(y_val, pred_val_KNN))\n",
    "        print(confusion_matrix(y_val, pred_val_MLP))\n",
    "\n",
    "    # Aggregating the average results across the folds\n",
    "    for l in range(0,5): \n",
    "        precision_scores_train_mean.append(mean(precision_scores_train[l]))\n",
    "        precision_scores_val_mean.append(mean(precision_scores_val[l]))\n",
    "        recall_scores_train_mean.append(mean(recall_scores_train[l]))\n",
    "        recall_scores_val_mean.append(mean(recall_scores_val[l]))\n",
    "        f1_scores_train_mean.append(mean(f1_scores_train[l]))\n",
    "        f1_scores_val_mean.append(mean(f1_scores_val[l]))\n",
    "\n",
    "    # Storing the results in a dataframe\n",
    "    model_results = pd.DataFrame(data={\n",
    "        'Train_precision': precision_scores_train_mean,\n",
    "        'Test_precision': precision_scores_val_mean,\n",
    "        'Train_recall': recall_scores_train_mean,\n",
    "        'Test_recall': recall_scores_val_mean,\n",
    "        'Train_f1_score': f1_scores_train_mean,\n",
    "        'Test_f1_score': f1_scores_val_mean,\n",
    "    }, index=[\"Decision Tree\",\"Random Forest\",\"XGBoost\", \"KNearestNeighbors\",\"Multi Layer Perceptron\"])\n",
    "\n",
    "    return model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb306304",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_prediction(model, X, y, num_features, cat_features, data_test, \n",
    "                    num_imputing_algorithm=XGBRegressor(), \n",
    "                    cat_imputing_algorithm=XGBClassifier(), scaling_outlier = False , \n",
    "                    scaler=MinMaxScaler()):\n",
    "\n",
    "    # Impute missing values\n",
    "    for column in num_features:\n",
    "        X, data_test = impute_missing_values(X,data_test,column, num_imputing_algorithm)\n",
    "\n",
    "    # Remove inconsistencies\n",
    "    inconsistent = X[(X['Age at Injury'] > 80) | (X[\"Age at Injury\"] < 16)].index\n",
    "    X.drop(inconsistent, inplace=True)\n",
    "    y.drop(inconsistent, inplace=True)\n",
    "\n",
    "    # Scale and remove outliers if specified\n",
    "    if scaling_outlier:\n",
    "        for column in num_features:\n",
    "            handle_outliers(X, column)\n",
    "            X, data_test = impute_missing_values(X,data_test, column, num_imputing_algorithm,validation = False)\n",
    "\n",
    "        for column in num_features:\n",
    "            scale_numerical(column, X, data_test, scaler)\n",
    "        \n",
    "    # Creating an ordinal variable\n",
    "    claim_carrier_categories(X, data_test)\n",
    "    \n",
    "    # Inputing missing values that might appear on data_test in the new variable\n",
    "    data_test, X = impute_missing_values(data_test, X, \"Carrier Claim Category\", cat_imputing_algorithm,validation= False)\n",
    "\n",
    "    # Categorical Prop Encoding\n",
    "    for cat_feature in cat_features:\n",
    "        categorical_prop_encode(X, data_test, cat_feature)\n",
    "        if scaling_outlier:\n",
    "            scale_numerical(\"Carrier Claim Category\", X, data_test, scaler)\n",
    "\n",
    "    # Fitting the model, making the predictions and reverting the claim injury types back to their string form\n",
    "    model.fit(X, y)\n",
    "    pred_test = model.predict(data_test)\n",
    "    pred_test = le.inverse_transform(pred_test)\n",
    "\n",
    "    # Saving the final submission dataframe with indexes of data_test\n",
    "    submission_df = pd.DataFrame({\n",
    "        \"Claim Injury Type\": pred_test\n",
    "    }, index=data_test.index)\n",
    "    \n",
    "    return submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3fa916c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Label enconding our target variable \n",
    "data[\"Claim Injury Type\"] = le.fit_transform(data[\"Claim Injury Type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f92e4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Dropping redundant variables that carry almost the same information (are extremely correlated (|0.8|))\n",
    "We believe it was better to keep Age at Injury than birth year since it should be more related to the injury claim type (it will be tested later)\n",
    "The same logic was applied to dropping the other two dates and two DSA variables since we believe Accident date to be more important'''\n",
    "\n",
    "data = data.loc[:, ~data.columns.isin(['Birth Year', 'Assembly Date', 'C-2 Date', 'Assembly Date DSA', 'First Hearing Date DSA'])]\n",
    "data_test = data_test.loc[:, ~data_test.columns.isin(['Birth Year', 'Assembly Date', 'C-2 Date', 'Assembly Date DSA', 'First Hearing Date DSA'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "61c9780a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Since the codes always seem to provide the same or more information than the descriptions (have more categories),\n",
    "and the codes are consistent (always only having 1 description for code, while descriptions may have multiple codes)\n",
    "And Crámer's V says they have a very high association\n",
    "we will drop the description columns.'''\n",
    "data.drop(['Industry Code Description','WCIO Cause of Injury Description','WCIO Nature of Injury Description','WCIO Part Of Body Description'], axis = 1,inplace = True)\n",
    "data_test.drop(['Industry Code Description','WCIO Cause of Injury Description','WCIO Nature of Injury Description','WCIO Part Of Body Description'], axis = 1,inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e0b67b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Dropping redundant variables that carry almost the same information (have an association above or equal to 0.8)\n",
    "We chose to keep County of Injury above Zip Code and District Name (these 3 have a high association) because it is the easist to interpret and the one we looked more in detail in the exploratory analysis\n",
    "We kept the new variable we made called body section because it keeps most of the same information of the body part code but with a much lower cardinality\n",
    "Lastly we only remove the variable Carrier Name in the function where we create the new variable with lower cardinality because it is need to create that new variable'''\n",
    "#\"WCIO Part Of Body Code\",\"District Name\"\n",
    "data.drop(['Zip Code',\"WCIO Part Of Body Code\",\"District Name\"], axis=1, inplace = True)\n",
    "data_test.drop([\"Zip Code\",\"WCIO Part Of Body Code\",\"District Name\"], axis=1 , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d0cad736",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = ['Age at Injury', 'Average Weekly Wage', 'IME-4 Count', 'Number of Dependents',\n",
    "                \"Accident Year\",\"Accident Month\",\"Accident Day\",\"Accident DayOfWeek\",\n",
    "                \"C-2 Date DSA\",\"C-3 Date DSA\" ,\"Accident Year\",\"Accident Month\",\n",
    "                \"Accident Day\",\"Accident DayOfWeek\",\"Accident Date\",\"C-3 Date\",\"First Hearing Date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a5a3fdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = [\n",
    "    \"Alternative Dispute Resolution\",\n",
    "    \"Carrier Type\",\n",
    "    \"County of Injury\",\n",
    "    \"Gender\",\n",
    "    \"Industry Code\",\n",
    "    \"Medical Fee Region\",\n",
    "    \"WCIO Cause of Injury Code\",\n",
    "    \"WCIO Nature of Injury Code\",\n",
    "    \"Age at Injury Category\",\n",
    "    \"Carrier Claim Category\",\n",
    "    \"Body Section\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "26014185-c798-4565-b6f4-c2ff8e2e4c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We remove the missing values in this variable since they are only 5 rows and would never make a big difference in the 600 000+ rows of the dataset\n",
    "data.dropna(axis= 0, inplace = True, subset=\"Alternative Dispute Resolution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f0380ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop([\"Claim Injury Type\",\"Agreement Reached\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "130bc8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[\"Claim Injury Type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ca4cdcba-054b-43fc-8d41-919cf8f0b507",
   "metadata": {},
   "outputs": [],
   "source": [
    "y2 = data[\"Agreement Reached\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f430371d-2ed7-4955-ba0d-7d061b421201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no missing values to input on Number of Dependents\n",
      "no missing values to input on Accident Year\n",
      "no missing values to input on Accident Month\n",
      "no missing values to input on Accident Day\n",
      "no missing values to input on Accident DayOfWeek\n",
      "no missing values to input on Age at Injury\n",
      "no missing values to input on Number of Dependents\n",
      "no missing values to input on Accident Month\n",
      "no missing values to input on Accident DayOfWeek\n",
      "no missing values to input on Accident Year\n",
      "no missing values to input on Accident Month\n",
      "no missing values to input on Accident Day\n",
      "no missing values to input on Accident DayOfWeek\n",
      "Done DT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   16.2s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   48.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done RF\n",
      "Done XGB\n",
      "Done KNN\n",
      "Iteration 1, loss = 1.05579236\n",
      "Iteration 2, loss = 1.00605287\n",
      "Iteration 3, loss = 1.00593230\n",
      "Iteration 4, loss = 1.00586784\n",
      "Iteration 5, loss = 1.00582081\n",
      "Iteration 6, loss = 1.00578257\n",
      "Iteration 7, loss = 1.00574961\n",
      "Iteration 8, loss = 1.00572040\n",
      "Iteration 9, loss = 1.00569374\n",
      "Iteration 10, loss = 1.00566915\n",
      "Iteration 11, loss = 1.00564611\n",
      "Iteration 12, loss = 1.00562450\n",
      "Iteration 13, loss = 1.00560400\n",
      "Iteration 14, loss = 1.00558443\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Done MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=12)]: Done 100 out of 100 | elapsed:    5.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done training predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 100 out of 100 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done validation predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gonca\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\gonca\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\gonca\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\gonca\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\gonca\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  743  1112   155   286   136    41     4    18]\n",
      " [ 3987 32427  6772 11768  2935   175    14   137]\n",
      " [  573  5564  1723  3545  1681   532    51   113]\n",
      " [  953  8693  3155  8014  4571  3369   464   482]\n",
      " [  218  1256   881  1600  3753  1718   194    36]\n",
      " [   23   206   127   190    85   156    33    22]\n",
      " [    0     7     3     4     2     0     3     1]\n",
      " [    5    32     5    24     7     2     0    19]]\n",
      "[[  950  1285     3   143   106     8     0     0]\n",
      " [  517 54183    24  2393  1037    55     0     6]\n",
      " [   45  9012   100  2641  1762   219     0     3]\n",
      " [   22 11551    87  9163  6746  2109     0    23]\n",
      " [    6   804    12  1140  7337   356     0     1]\n",
      " [    0    73     7   364   222   176     0     0]\n",
      " [    0     4     0    13     0     3     0     0]\n",
      " [    0    19     1    66     6     0     0     2]]\n",
      "[[ 1077  1170     3    98   122    24     0     1]\n",
      " [  647 52731    32  2278  2199   282     2    44]\n",
      " [   76  8746    89  2389  1985   449    13    35]\n",
      " [   66 10387   152  8799  7330  2677   153   137]\n",
      " [   14   712    29   908  6919  1039    31     4]\n",
      " [    3    82    12   339   209   182    12     3]\n",
      " [    0     3     0    12     2     3     0     0]\n",
      " [    0    28     1    36     3     4     0    22]]\n",
      "[[  718  1441    13   181   142     0     0     0]\n",
      " [  478 53895   109  2635  1098     0     0     0]\n",
      " [   20  8779   222  3191  1570     0     0     0]\n",
      " [   21 12354   454 11162  5701     9     0     0]\n",
      " [    6   830    80  3757  4981     2     0     0]\n",
      " [    0    43    18   485   295     1     0     0]\n",
      " [    0     0     3    15     2     0     0     0]\n",
      " [    0     9     1    65    19     0     0     0]]\n",
      "[[  149  1805     0   419   122     0     0     0]\n",
      " [  178 54214     0  2802  1021     0     0     0]\n",
      " [    4  9190     0  3408  1180     0     0     0]\n",
      " [   12 13192     0 13048  3449     0     0     0]\n",
      " [    5  1315     1  4364  3971     0     0     0]\n",
      " [    2    34     0   669   137     0     0     0]\n",
      " [    0     1     0    18     1     0     0     0]\n",
      " [    0    21     0    46    27     0     0     0]]\n",
      "no missing values to input on Number of Dependents\n",
      "no missing values to input on Accident Year\n",
      "no missing values to input on Accident Month\n",
      "no missing values to input on Accident Day\n",
      "no missing values to input on Accident DayOfWeek\n",
      "no missing values to input on Age at Injury\n",
      "no missing values to input on Number of Dependents\n",
      "no missing values to input on Accident Month\n",
      "no missing values to input on Accident Day\n",
      "no missing values to input on Accident DayOfWeek\n",
      "no missing values to input on Accident Month\n",
      "no missing values to input on Accident Day\n",
      "no missing values to input on Accident DayOfWeek\n",
      "Done DT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    9.6s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   30.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done RF\n",
      "Done XGB\n",
      "Done KNN\n",
      "Iteration 1, loss = 1.06170315\n",
      "Iteration 2, loss = 1.00754073\n",
      "Iteration 3, loss = 1.00688177\n",
      "Iteration 4, loss = 1.00665206\n",
      "Iteration 5, loss = 1.00653312\n",
      "Iteration 6, loss = 1.00645682\n",
      "Iteration 7, loss = 1.00640121\n",
      "Iteration 8, loss = 1.00635704\n",
      "Iteration 9, loss = 1.00631989\n",
      "Iteration 10, loss = 1.00628745\n",
      "Iteration 11, loss = 1.00625838\n",
      "Iteration 12, loss = 1.00623177\n",
      "Iteration 13, loss = 1.00620713\n",
      "Iteration 14, loss = 1.00618412\n",
      "Iteration 15, loss = 1.00616232\n",
      "Iteration 16, loss = 1.00614160\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Done MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=12)]: Done 100 out of 100 | elapsed:    3.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done training predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 100 out of 100 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done validation predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gonca\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\gonca\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\gonca\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\gonca\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\gonca\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  901  1028   224   237    86    16     0     3]\n",
      " [ 1815 38130  8550  7949  1625    92    11    43]\n",
      " [  289  5573  2443  3363  1691   369     9    44]\n",
      " [  695  6199  5837  9099  5530  2111    54   176]\n",
      " [  130   752  1931  2313  3526   946    26    32]\n",
      " [   50   118   212   307   108    31     0    17]\n",
      " [    3     1     5     9     1     0     0     0]\n",
      " [    2    23    23    38     4     0     0     4]]\n",
      "[[ 1072  1107    45   183    86     2     0     0]\n",
      " [  418 52737   986  3007  1059     8     0     0]\n",
      " [   13  7370   577  3881  1893    47     0     0]\n",
      " [   13  6569  1308 15811  5636   363     0     1]\n",
      " [    4   399   360  3747  5088    58     0     0]\n",
      " [    0    32    51   696    64     0     0     0]\n",
      " [    0     2     1    15     1     0     0     0]\n",
      " [    0    22     4    68     0     0     0     0]]\n",
      "[[ 1180   983   117    95   101    14     0     5]\n",
      " [  504 47741  5871  2484  1467    91     0    57]\n",
      " [   32  7331   768  2897  2424   309     0    20]\n",
      " [   54  6269  5035  7745  8117  2381     0   100]\n",
      " [    7   439  1628  2009  5063   509     1     0]\n",
      " [    0    37   214   514    47    31     0     0]\n",
      " [    0     1     0    16     1     0     0     1]\n",
      " [    1    25    14    46     0     0     0     8]]\n",
      "[[ 1042  1126    32   194   101     0     0     0]\n",
      " [  461 53957   323  2295  1179     0     0     0]\n",
      " [   14  8396   448  3540  1383     0     0     0]\n",
      " [   25 11664   953 13650  3408     1     0     0]\n",
      " [    9   764   211  4923  3749     0     0     0]\n",
      " [    0    55    36   605   147     0     0     0]\n",
      " [    0     1     1    13     4     0     0     0]\n",
      " [    0    11     4    74     5     0     0     0]]\n",
      "[[   12  2102     0   339    42     0     0     0]\n",
      " [    6 55260     0  2777   172     0     0     0]\n",
      " [    0  9419     0  4075   287     0     0     0]\n",
      " [    1 15239     0 13698   763     0     0     0]\n",
      " [    0  2515     0  6250   891     0     0     0]\n",
      " [    0   188     0   619    36     0     0     0]\n",
      " [    0     8     0    10     1     0     0     0]\n",
      " [    0    30     0    58     6     0     0     0]]\n",
      "no missing values to input on Number of Dependents\n",
      "no missing values to input on Accident Year\n",
      "no missing values to input on Accident Month\n",
      "no missing values to input on Accident Day\n",
      "no missing values to input on Accident DayOfWeek\n",
      "no missing values to input on Age at Injury\n",
      "no missing values to input on Number of Dependents\n",
      "no missing values to input on Accident Month\n",
      "no missing values to input on Accident DayOfWeek\n",
      "no missing values to input on Accident Month\n",
      "no missing values to input on Accident Day\n",
      "no missing values to input on Accident DayOfWeek\n",
      "Done DT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    9.3s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   30.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done RF\n",
      "Done XGB\n",
      "Done KNN\n",
      "Iteration 1, loss = 1.06629905\n",
      "Iteration 2, loss = 1.01283265\n",
      "Iteration 3, loss = 1.01236282\n",
      "Iteration 4, loss = 1.01214060\n",
      "Iteration 5, loss = 1.01200066\n",
      "Iteration 6, loss = 1.01189975\n",
      "Iteration 7, loss = 1.01182110\n",
      "Iteration 8, loss = 1.01175681\n",
      "Iteration 9, loss = 1.01170241\n",
      "Iteration 10, loss = 1.01165519\n",
      "Iteration 11, loss = 1.01161352\n",
      "Iteration 12, loss = 1.01157609\n",
      "Iteration 13, loss = 1.01154204\n",
      "Iteration 14, loss = 1.01151080\n",
      "Iteration 15, loss = 1.01148186\n",
      "Iteration 16, loss = 1.01145484\n",
      "Iteration 17, loss = 1.01142946\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Done MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=12)]: Done 100 out of 100 | elapsed:    3.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done training predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 100 out of 100 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done validation predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gonca\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\gonca\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\gonca\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\gonca\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\gonca\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\gonca\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  992   880   272   201   122    24     1     4]\n",
      " [ 1999 36509 10577  6885  2066   157     4    18]\n",
      " [  335  5568  2306  2833  2311   387    13    28]\n",
      " [  500  5861  6411  6187  7466  2989    57   230]\n",
      " [  128  1071  3003  2875  2003   559     7    10]\n",
      " [   36   103   141   424   119    16     0     3]\n",
      " [    1     4     5     6     3     0     0     0]\n",
      " [    2    21    27    34     5     2     0     3]]\n",
      "[[ 1091  1064    91   105   139     6     0     0]\n",
      " [  391 51000  2899  2463  1442    20     0     0]\n",
      " [   11  7666   633  3012  2382    77     0     0]\n",
      " [   23  7123  3709 10161  7803   881     0     1]\n",
      " [    5   506  1356  4061  3689    39     0     0]\n",
      " [    0    21     8   755    58     0     0     0]\n",
      " [    0     1     1    14     3     0     0     0]\n",
      " [    0    13     6    73     2     0     0     0]]\n",
      "[[ 1131   974   183    68   130     8     0     2]\n",
      " [  426 43109  9908  2784  1941    36     0    11]\n",
      " [   27  7249  1123  2363  2862   148     0     9]\n",
      " [   88  6300  7692  5105  9275  1165     0    76]\n",
      " [    4   450  2486  3591  3050    75     0     0]\n",
      " [    0    21    32   727    62     0     0     0]\n",
      " [    0     1     1    14     3     0     0     0]\n",
      " [    0    16     6    69     1     0     0     2]]\n",
      "[[ 1062  1102    34   211    87     0     0     0]\n",
      " [  454 53631   460  2311  1359     0     0     0]\n",
      " [   12  8573   462  3513  1221     0     0     0]\n",
      " [   30 11520  1103 14034  3014     0     0     0]\n",
      " [    6   876   302  4903  3569     0     0     0]\n",
      " [    1    39    24   652   126     0     0     0]\n",
      " [    0     2     1    11     5     0     0     0]\n",
      " [    0    14     5    64    11     0     0     0]]\n",
      "[[    1  1973     3   516     3     0     0     0]\n",
      " [    6 54652    10  3501    46     0     0     0]\n",
      " [    0  9361     2  4354    64     0     0     0]\n",
      " [   30 12503     3 17046   119     0     0     0]\n",
      " [    0  1963     1  7378   314     0     0     0]\n",
      " [    0    14     0   821     7     0     0     0]\n",
      " [    0     2     0    17     0     0     0     0]\n",
      " [    0    15     0    79     0     0     0     0]]\n",
      "no missing values to input on Number of Dependents\n",
      "no missing values to input on Accident Year\n",
      "no missing values to input on Accident Month\n",
      "no missing values to input on Accident Day\n",
      "no missing values to input on Accident DayOfWeek\n",
      "no missing values to input on Age at Injury\n",
      "no missing values to input on Number of Dependents\n",
      "no missing values to input on Accident Month\n",
      "no missing values to input on Accident Day\n",
      "no missing values to input on Accident DayOfWeek\n",
      "no missing values to input on Accident Year\n",
      "no missing values to input on Accident Month\n",
      "no missing values to input on Accident Day\n",
      "no missing values to input on Accident DayOfWeek\n",
      "Done DT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    9.4s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   31.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done RF\n",
      "Done XGB\n",
      "Done KNN\n",
      "Iteration 1, loss = 1.06069674\n",
      "Iteration 2, loss = 1.00504154\n",
      "Iteration 3, loss = 1.00480554\n",
      "Iteration 4, loss = 1.00468897\n",
      "Iteration 5, loss = 1.00461212\n",
      "Iteration 6, loss = 1.00455479\n",
      "Iteration 7, loss = 1.00450846\n",
      "Iteration 8, loss = 1.00446930\n",
      "Iteration 9, loss = 1.00443513\n",
      "Iteration 10, loss = 1.00440443\n",
      "Iteration 11, loss = 1.00437653\n",
      "Iteration 12, loss = 1.00435088\n",
      "Iteration 13, loss = 1.00432700\n",
      "Iteration 14, loss = 1.00430459\n",
      "Iteration 15, loss = 1.00428340\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Done MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=12)]: Done 100 out of 100 | elapsed:    3.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done training predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 100 out of 100 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done validation predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gonca\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\gonca\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\gonca\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\gonca\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\gonca\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\gonca\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  966   966   224   184   128    27     0     1]\n",
      " [ 1559 37849  8850  6319  3473   130     0    34]\n",
      " [  242  5112  2130  2949  2820   481     0    47]\n",
      " [  584  5078  5947  7396  7936  2584    11   166]\n",
      " [   98  1046  3124  3058  1877   427     8    18]\n",
      " [    5   120   225   381    93    12     0     6]\n",
      " [    1     2     3     9     4     0     0     0]\n",
      " [    0    28    21    33     5     4     0     3]]\n",
      "[[ 1186   997    78    96   137     2     0     0]\n",
      " [  363 52887  1365  1819  1774     6     0     0]\n",
      " [   10  7364   538  2656  3194    19     0     0]\n",
      " [   14  7161  3480  9295  9555   197     0     0]\n",
      " [    4   571  1846  4960  2265    10     0     0]\n",
      " [    0    18    22   740    62     0     0     0]\n",
      " [    0     0     0    17     2     0     0     0]\n",
      " [    0    22     8    62     2     0     0     0]]\n",
      "[[ 1297   846   140    71   128    11     0     3]\n",
      " [  458 46728  6635  1305  3025    42     0    21]\n",
      " [   20  6962   876  2083  3671   153     0    16]\n",
      " [   34  5947  6645  5439 10569   981     0    87]\n",
      " [    6   449  2462  4329  2369    39     0     2]\n",
      " [    0    12    44   736    50     0     0     0]\n",
      " [    0     1     1    15     2     0     0     0]\n",
      " [    0    19    12    57     1     0     0     5]]\n",
      "[[ 1160   965    43   191   137     0     0     0]\n",
      " [  453 53761   254  2153  1593     0     0     0]\n",
      " [   10  8151   280  3248  2092     0     0     0]\n",
      " [   56 11574   896 12169  5007     0     0     0]\n",
      " [   10   986   374  5567  2719     0     0     0]\n",
      " [    0    37    36   673    96     0     0     0]\n",
      " [    0     0     0    16     3     0     0     0]\n",
      " [    0     9     1    72    12     0     0     0]]\n",
      "[[  131  1724     1   572    68     0     0     0]\n",
      " [  362 53602     2  3750   498     0     0     0]\n",
      " [   27  8296     2  5012   444     0     0     0]\n",
      " [  334 11468    15 17458   427     0     0     0]\n",
      " [   37  1447     3  6947  1222     0     0     0]\n",
      " [    1     8     0   805    28     0     0     0]\n",
      " [    0     0     0    16     3     0     0     0]\n",
      " [    1     9     0    70    14     0     0     0]]\n",
      "no missing values to input on Number of Dependents\n",
      "no missing values to input on Accident Year\n",
      "no missing values to input on Accident Month\n",
      "no missing values to input on Accident Day\n",
      "no missing values to input on Accident DayOfWeek\n",
      "no missing values to input on Age at Injury\n",
      "no missing values to input on Number of Dependents\n",
      "no missing values to input on Accident Month\n",
      "no missing values to input on Accident Day\n",
      "no missing values to input on Accident DayOfWeek\n",
      "no missing values to input on Accident Year\n",
      "no missing values to input on Accident Month\n",
      "no missing values to input on Accident Day\n",
      "no missing values to input on Accident DayOfWeek\n",
      "Done DT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    9.6s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   33.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done RF\n",
      "Done XGB\n",
      "Done KNN\n",
      "Iteration 1, loss = 1.06043166\n",
      "Iteration 2, loss = 1.00364842\n",
      "Iteration 3, loss = 1.00357320\n",
      "Iteration 4, loss = 1.00351931\n",
      "Iteration 5, loss = 1.00347541\n",
      "Iteration 6, loss = 1.00343761\n",
      "Iteration 7, loss = 1.00340389\n",
      "Iteration 8, loss = 1.00337331\n",
      "Iteration 9, loss = 1.00334511\n",
      "Iteration 10, loss = 1.00331882\n",
      "Iteration 11, loss = 1.00329418\n",
      "Iteration 12, loss = 1.00327082\n",
      "Iteration 13, loss = 1.00324864\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Done MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=12)]: Done 100 out of 100 | elapsed:    4.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done training predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 100 out of 100 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done validation predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gonca\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\gonca\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\gonca\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\gonca\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\gonca\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  918   632   745   177    21     0     0     2]\n",
      " [  652 11615 41974  3696   263     7     0     7]\n",
      " [   70  1987 10202  1363   150     6     0     3]\n",
      " [  152  4097 20973  3970   484    19     0     7]\n",
      " [   80  1358  4517  3081   601    17     0     2]\n",
      " [    8    59   318   381    71     3     0     2]\n",
      " [    0     0     8     9     3     0     0     0]\n",
      " [    3    11    31    43     5     0     0     1]]\n",
      "[[ 1087   571   759    71     7     0     0     0]\n",
      " [  152  7572 50024   413    53     0     0     0]\n",
      " [    3   444 13076   233    25     0     0     0]\n",
      " [    4  1185 27245  1242    26     0     0     0]\n",
      " [    1   392  5222  3588   453     0     0     0]\n",
      " [    0    11   219   584    28     0     0     0]\n",
      " [    0     1     3    14     2     0     0     0]\n",
      " [    0    10    35    49     0     0     0     0]]\n",
      "[[ 1087   429   932    37    10     0     0     0]\n",
      " [  218 11613 46052   264    66     0     0     1]\n",
      " [    2   836 12721   171    51     0     0     0]\n",
      " [    8  1416 27235   945    98     0     0     0]\n",
      " [    3   375  5435  3257   586     0     0     0]\n",
      " [    0    12   249   541    40     0     0     0]\n",
      " [    0     0     6    13     1     0     0     0]\n",
      " [    1    12    38    43     0     0     0     0]]\n",
      "[[  995  1087    84   293    36     0     0     0]\n",
      " [  225 53059   813  3400   717     0     0     0]\n",
      " [    5  8279   828  4071   598     0     0     0]\n",
      " [   16 11529  2076 15421   660     0     0     0]\n",
      " [    5  1132   647  6008  1864     0     0     0]\n",
      " [    0    30    60   719    33     0     0     0]\n",
      " [    0     1     1    14     4     0     0     0]\n",
      " [    0     6     7    76     5     0     0     0]]\n",
      "[[    0  1657    80   752     6     0     0     0]\n",
      " [    1 52546   244  5358    65     0     0     0]\n",
      " [    0  8204    41  5502    34     0     0     0]\n",
      " [    0 11363   180 18053   106     0     0     0]\n",
      " [    0   951    50  8432   223     0     0     0]\n",
      " [    0     5     2   826     9     0     0     0]\n",
      " [    0     0     1    19     0     0     0     0]\n",
      " [    0     5     2    83     4     0     0     0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gonca\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\gonca\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "results = cv_scores(X, y,num_features,cat_features,scaling_outlier = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f4ffce66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train_precision</th>\n",
       "      <th>Test_precision</th>\n",
       "      <th>Train_recall</th>\n",
       "      <th>Test_recall</th>\n",
       "      <th>Train_f1_score</th>\n",
       "      <th>Test_f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.999950</td>\n",
       "      <td>0.213073</td>\n",
       "      <td>0.999990</td>\n",
       "      <td>0.224442</td>\n",
       "      <td>0.999970</td>\n",
       "      <td>0.196063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.999973</td>\n",
       "      <td>0.316299</td>\n",
       "      <td>0.999958</td>\n",
       "      <td>0.267772</td>\n",
       "      <td>0.999966</td>\n",
       "      <td>0.252458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.795255</td>\n",
       "      <td>0.291958</td>\n",
       "      <td>0.580957</td>\n",
       "      <td>0.259127</td>\n",
       "      <td>0.623074</td>\n",
       "      <td>0.239476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNearestNeighbors</th>\n",
       "      <td>0.381528</td>\n",
       "      <td>0.311876</td>\n",
       "      <td>0.302539</td>\n",
       "      <td>0.268804</td>\n",
       "      <td>0.314318</td>\n",
       "      <td>0.272512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multi Layer Perceptron</th>\n",
       "      <td>0.286770</td>\n",
       "      <td>0.243040</td>\n",
       "      <td>0.203047</td>\n",
       "      <td>0.202977</td>\n",
       "      <td>0.188041</td>\n",
       "      <td>0.188804</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Train_precision  Test_precision  Train_recall  \\\n",
       "Decision Tree                  0.999950        0.213073      0.999990   \n",
       "Random Forest                  0.999973        0.316299      0.999958   \n",
       "XGBoost                        0.795255        0.291958      0.580957   \n",
       "KNearestNeighbors              0.381528        0.311876      0.302539   \n",
       "Multi Layer Perceptron         0.286770        0.243040      0.203047   \n",
       "\n",
       "                        Test_recall  Train_f1_score  Test_f1_score  \n",
       "Decision Tree              0.224442        0.999970       0.196063  \n",
       "Random Forest              0.267772        0.999966       0.252458  \n",
       "XGBoost                    0.259127        0.623074       0.239476  \n",
       "KNearestNeighbors          0.268804        0.314318       0.272512  \n",
       "Multi Layer Perceptron     0.202977        0.188041       0.188804  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the results\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "923c21bd-9847-47e1-91ff-70b453b3b311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no missing values to input on Number of Dependents\n",
      "no missing values to input on Accident Year\n",
      "no missing values to input on Accident Month\n",
      "no missing values to input on Accident Day\n",
      "no missing values to input on Accident DayOfWeek\n",
      "no missing values to input on Alternative Dispute Resolution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gonca\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [17:03:12] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:52: Empty dataset at worker: 0\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Claim Injury Type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Claim Identifier</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6165911</th>\n",
       "      <td>2. NON-COMP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6166141</th>\n",
       "      <td>2. NON-COMP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6165907</th>\n",
       "      <td>2. NON-COMP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6166047</th>\n",
       "      <td>2. NON-COMP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6166102</th>\n",
       "      <td>2. NON-COMP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6553137</th>\n",
       "      <td>3. MED ONLY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6553119</th>\n",
       "      <td>4. TEMPORARY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6553542</th>\n",
       "      <td>4. TEMPORARY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6553455</th>\n",
       "      <td>4. TEMPORARY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6553594</th>\n",
       "      <td>3. MED ONLY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>387975 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Claim Injury Type\n",
       "Claim Identifier                  \n",
       "6165911                2. NON-COMP\n",
       "6166141                2. NON-COMP\n",
       "6165907                2. NON-COMP\n",
       "6166047                2. NON-COMP\n",
       "6166102                2. NON-COMP\n",
       "...                            ...\n",
       "6553137                3. MED ONLY\n",
       "6553119               4. TEMPORARY\n",
       "6553542               4. TEMPORARY\n",
       "6553455               4. TEMPORARY\n",
       "6553594                3. MED ONLY\n",
       "\n",
       "[387975 rows x 1 columns]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose best model from KFold of cross validation\n",
    "# Train model on whole train and predict test data\n",
    "submission = test_prediction(XGBClassifier(),X,y,num_features,cat_features,data_test)\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "fe86d483",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export to csv\n",
    "submission.to_csv(\"Submission.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
