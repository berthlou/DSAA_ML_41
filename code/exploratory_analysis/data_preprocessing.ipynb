{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e75793a0-91fe-4a25-bb66-e5f66111ef87",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "This notebook contains code to preprocess the dataset (problem solving, outlier handling, missing values etc.) and the feature creation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "665702f6-2066-4a96-a2b4-40fe6f615c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a6f12d-25e1-429b-a0d3-f5d1ff7db900",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "386351dc-bb0c-467d-ae63-08a9808c885b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Louis\\AppData\\Local\\Temp\\ipykernel_56372\\3698058545.py:2: DtypeWarning: Columns (29) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_train = pd.read_csv(\"../../data/train_data.csv\")\n"
     ]
    }
   ],
   "source": [
    "# Loading data\n",
    "df_train = pd.read_csv(\"../../data/train_data.csv\")\n",
    "df_test = pd.read_csv(\"../../data/test_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc9c5ab-d89c-49c1-96be-7c4bbed43e57",
   "metadata": {},
   "source": [
    "# TODO: Copy to explo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c4952660-74bd-4d72-a892-c1f4a345659c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare(df, date_columns=None, code_identifiers=['Code']):\n",
    "    \"\"\"\n",
    "    Prepare the DataFrame by:\n",
    "      - Converting specified date columns to datetime.\n",
    "      - Casting columns with specified keywords (e.g., 'Code') in their names to categorical data type.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The DataFrame to prepare.\n",
    "        date_columns (list): List of columns to convert to datetime. Default is None.\n",
    "        code_identifiers (list): List of keywords to identify code columns. Default is ['Code'].\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: The modified DataFrame with date conversions and categorical castings applied.\n",
    "    \"\"\"\n",
    "    # Convert specified columns to datetime\n",
    "    if date_columns:\n",
    "        for col in date_columns:\n",
    "            df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "    \n",
    "    # Convert code_identifiers to lowercase for case-insensitive matching\n",
    "    code_identifiers = [keyword.lower() for keyword in code_identifiers]\n",
    "\n",
    "    # Cast columns with keywords in their names to categorical\n",
    "    for col in df.columns:\n",
    "        if any(keyword in col.lower() for keyword in code_identifiers):\n",
    "            if pd.api.types.is_numeric_dtype(df[col]):\n",
    "                df[col] = df[col].astype('category')\n",
    "                print(f\"Column '{col}' cast to 'category' data type.\")\n",
    "            else:\n",
    "                print(f\"Column '{col}' already non-numeric, no casting applied.\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e080f522-f518-42e7-a83d-7622d76b10af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'Industry Code' cast to 'category' data type.\n",
      "Column 'Industry Code Description' already non-numeric, no casting applied.\n",
      "Column 'WCIO Cause of Injury Code' cast to 'category' data type.\n",
      "Column 'WCIO Nature of Injury Code' cast to 'category' data type.\n",
      "Column 'WCIO Part Of Body Code' cast to 'category' data type.\n",
      "Column 'Zip Code' already non-numeric, no casting applied.\n",
      "Column 'Industry Code' cast to 'category' data type.\n",
      "Column 'Industry Code Description' already non-numeric, no casting applied.\n",
      "Column 'WCIO Cause of Injury Code' cast to 'category' data type.\n",
      "Column 'WCIO Nature of Injury Code' cast to 'category' data type.\n",
      "Column 'WCIO Part Of Body Code' cast to 'category' data type.\n",
      "Column 'Zip Code' already non-numeric, no casting applied.\n"
     ]
    }
   ],
   "source": [
    "# Define columns for date conversion\n",
    "date_columns = ['Accident Date', 'Assembly Date', 'C-2 Date', 'C-3 Date', 'First Hearing Date']\n",
    "\n",
    "# Prepare the training and test DataFrames\n",
    "df_train = prepare(df_train, date_columns=date_columns)\n",
    "df_test = prepare(df_test, date_columns=date_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00278c8b-b3b5-4a7d-82ee-6faade9f297a",
   "metadata": {},
   "source": [
    "## Individual Feature Processing\n",
    "- Unifying missing data with NaN\n",
    "- Removing outliers\n",
    "- etc.\n",
    "\n",
    "Missing data will be handled in a later step (Imputer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e92604d8-8af8-4903-8e47-98b42b59f8f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Accident Date                         datetime64[ns]\n",
       "Age at Injury                                float64\n",
       "Alternative Dispute Resolution                object\n",
       "Assembly Date                         datetime64[ns]\n",
       "Attorney/Representative                       object\n",
       "Average Weekly Wage                          float64\n",
       "Birth Year                                   float64\n",
       "C-2 Date                              datetime64[ns]\n",
       "C-3 Date                              datetime64[ns]\n",
       "Carrier Name                                  object\n",
       "Carrier Type                                  object\n",
       "Claim Identifier                               int64\n",
       "Claim Injury Type                             object\n",
       "County of Injury                              object\n",
       "COVID-19 Indicator                            object\n",
       "District Name                                 object\n",
       "First Hearing Date                    datetime64[ns]\n",
       "Gender                                        object\n",
       "IME-4 Count                                  float64\n",
       "Industry Code                               category\n",
       "Industry Code Description                     object\n",
       "Medical Fee Region                            object\n",
       "OIICS Nature of Injury Description           float64\n",
       "WCIO Cause of Injury Code                   category\n",
       "WCIO Cause of Injury Description              object\n",
       "WCIO Nature of Injury Code                  category\n",
       "WCIO Nature of Injury Description             object\n",
       "WCIO Part Of Body Code                      category\n",
       "WCIO Part Of Body Description                 object\n",
       "Zip Code                                      object\n",
       "Agreement Reached                            float64\n",
       "WCB Decision                                  object\n",
       "Number of Dependents                         float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c76e6be-9275-43d1-b2d5-91082cb99ec6",
   "metadata": {},
   "source": [
    "**Age at injury**:\n",
    "Impossible age of 0 replace with missing value (NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "614c05ee-2736-4316-a708-318038414046",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Age at Injury'] = df_train['Age at Injury'].replace(0, np.nan)\n",
    "df_test['Age at Injury'] = df_test['Age at Injury'].replace(0, np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad80545-d265-4cdc-bb10-90a4123101b4",
   "metadata": {},
   "source": [
    "We consider any age below 14 or over 80 to be erroneous as it is not possible to be legally working at that age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7d55f68d-5e56-484b-8a43-59b6e1062f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop(df_train[(df_train['Age at Injury'] < 14) | (df_train['Age at Injury'] > 80)].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ede0004-bdf0-4b26-8ae1-326841acba29",
   "metadata": {},
   "source": [
    "**Birth year**: Impossible birth year of 0 replace with missing value (NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1045b4cb-c44f-4abb-975b-282ae3257b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Birth Year'] = df_train['Birth Year'].replace(0, np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf09cbaf-c43b-4380-83d6-f1c108f64dc9",
   "metadata": {},
   "source": [
    "**Carrier type**: Replace UNKNOWN with NaN to be handled by the imputer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9152aae2-5499-453e-a2aa-731cfaa61e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace UNKNOWN with Nan\n",
    "df_train['Carrier Type'] = df_train['Carrier Type'].replace(\"UNKNOWN\", np.nan)\n",
    "df_test['Carrier Type'] = df_test['Carrier Type'].replace(\"UNKNOWN\", np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f32f76-fcb8-44a7-8ad3-c703285c4187",
   "metadata": {},
   "source": [
    "**Attorney representation**: Replace Y/N Strings with boolean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d8b61b6c-6b38-43d4-b4fb-ebe575b46f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'Y' with True, 'N' with False, and preserve NaNs\n",
    "df_train['Attorney/Representative'] = df_train['Attorney/Representative'].replace({'Y': True, 'N': False})\n",
    "\n",
    "# Now convert to nullable boolean type\n",
    "df_train['Attorney/Representative'] = df_train['Attorney/Representative'].astype(\"boolean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "26f9407d-1d20-41a9-8e1e-b0bafc37fc3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Louis\\AppData\\Local\\Temp\\ipykernel_56372\\3794846623.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_test['Attorney/Representative'] = df_test['Attorney/Representative'].replace({'Y': True, 'N': False})\n"
     ]
    }
   ],
   "source": [
    "# Replace 'Y' with True, 'N' with False, and preserve NaNs\n",
    "df_test['Attorney/Representative'] = df_test['Attorney/Representative'].replace({'Y': True, 'N': False})\n",
    "\n",
    "# Now convert to nullable boolean type\n",
    "df_test['Attorney/Representative'] = df_test['Attorney/Representative'].astype(\"boolean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec29580-a2c6-46ba-b1b6-4838d517d5d9",
   "metadata": {},
   "source": [
    "**Alternative Dispute Resolution**: Replace Y/N Strings with boolean and Unknown with NaN to be handled by imputer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "61a3802d-fc50-41ca-ada1-1319d1a109bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Alternative Dispute Resolution'] = df_train['Alternative Dispute Resolution'].replace(\"U\", np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e8b0cab1-888e-4e15-977b-e7c15778cf5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Alternative Dispute Resolution'] = df_train['Alternative Dispute Resolution'].replace({'Y': True, 'N': False})\n",
    "df_train['Alternative Dispute Resolution'] = df_train['Alternative Dispute Resolution'].astype(\"boolean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1e760a14-7cc5-42a3-a380-093585337ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['Alternative Dispute Resolution'] = df_test['Alternative Dispute Resolution'].replace(\"U\", np.nan)\n",
    "df_test['Alternative Dispute Resolution'] = df_test['Alternative Dispute Resolution'].replace({'Y': True, 'N': False})\n",
    "df_test['Alternative Dispute Resolution'] = df_test['Alternative Dispute Resolution'].astype(\"boolean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286b4443-a4f3-4d15-b11a-ca375ed2aeaf",
   "metadata": {},
   "source": [
    "**Carrier Name**: Too many names - high dimensionality feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "186b8e3f-b762-4752-8ef2-0185e4a0a471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace unknowns with \"others\"?\n",
    "# Will be treated in New Features Section"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4ffee6-b521-4cd7-8719-fa287a4ffce1",
   "metadata": {},
   "source": [
    "**Claim Identifier**: Contains duplicates - is the ID column of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "243325aa-f1fc-4875-8330-35aa716365b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Completely remove duplicates in \"Claim Identifier\" from train\n",
    "df_train = df_train[~df_train['Claim Identifier'].duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069db2c0-7a88-4eaf-9877-0b3271d40c45",
   "metadata": {},
   "source": [
    "**IME-4 Count**: Outlier handling - Anything over 10 is considered extreme/high as seen in exploratory analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6d3b5ac0-f397-4ccc-9f93-4e8aec0b9756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cap high values to 10\n",
    "lower_bound = 0\n",
    "upper_bound = 10\n",
    "df_train['IME-4 Count'] = df_train['IME-4 Count'].apply(lambda x: min(max(x, lower_bound), upper_bound))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab6d1ce-ea66-4792-a072-c3293bd9ac1f",
   "metadata": {},
   "source": [
    "**Covid indicator**: Replace Y/N Strings with boolean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "20169d44-bbc1-4ed2-b0da-745f4ce97ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Louis\\AppData\\Local\\Temp\\ipykernel_56372\\1821571298.py:6: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_test['COVID-19 Indicator'] = df_test['COVID-19 Indicator'].replace({'Y': True, 'N': False})\n"
     ]
    }
   ],
   "source": [
    "df_train['COVID-19 Indicator'] = df_train['COVID-19 Indicator'].replace({'Y': True, 'N': False})\n",
    "\n",
    "# Now convert to nullable boolean type\n",
    "df_train['COVID-19 Indicator'] = df_train['COVID-19 Indicator'].astype(\"boolean\")\n",
    "\n",
    "df_test['COVID-19 Indicator'] = df_test['COVID-19 Indicator'].replace({'Y': True, 'N': False})\n",
    "\n",
    "# Now convert to nullable boolean type\n",
    "df_test['COVID-19 Indicator'] = df_test['COVID-19 Indicator'].astype(\"boolean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e236cb05-9852-4166-aa07-0587c9e28a97",
   "metadata": {},
   "source": [
    "**Average Weekly Wage**: Outlier handling - anything over 30'000 is considered extreme/high as seen exploratory analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f639e448-b5dc-4cb2-a7e7-af836b5fc2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_bound = 3.0e+04\n",
    "lower_bound = 0\n",
    "df_train['Average Weekly Wage'] = df_train['Average Weekly Wage'].apply(lambda x: min(max(x, lower_bound), upper_bound))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4d8667-ec23-48a1-b73a-acb2b34acfaf",
   "metadata": {},
   "source": [
    "**Medical Fee Region**: Replace Unknown with NaN to be handled by Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c685eaf4-4dd8-408e-8bd9-d9d88464c468",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Medical Fee Region'] = df_train['Medical Fee Region'].replace(\"UK\", np.nan)\n",
    "df_test['Medical Fee Region'] = df_test['Medical Fee Region'].replace(\"UK\", np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498da336-eb07-47ac-bbad-5cde57b2c98d",
   "metadata": {},
   "source": [
    "**WCIO Part Of Body Code**: Treat negative numerical codes by applying absolute function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1b8f9e7c-246e-4e97-a4e6-b148642a8f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted all 'WCIO Part Of Body Code' values to positive and restored as categorical.\n"
     ]
    }
   ],
   "source": [
    "# Temporarily convert to numeric to apply absolute value, then convert back to category\n",
    "df_train[\"WCIO Part Of Body Code\"] = pd.to_numeric(df_train[\"WCIO Part Of Body Code\"], errors='coerce').abs().astype('category')\n",
    "df_test[\"WCIO Part Of Body Code\"] = pd.to_numeric(df_test[\"WCIO Part Of Body Code\"], errors='coerce').abs().astype('category')\n",
    "\n",
    "print(\"Converted all 'WCIO Part Of Body Code' values to positive and restored as categorical.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d42cc2-768e-42b0-a47a-ee6b6e3e961a",
   "metadata": {},
   "source": [
    "**Zip Code**: Setting placeholder ZIP codes as NaN to be treated by imputer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "05d9865d-6aab-48c7-960e-4929d5ad535f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced placeholder values with NaN in 'Zip Code'.\n"
     ]
    }
   ],
   "source": [
    "# Replace placeholder values with NaN in the original DataFrame\n",
    "df_train.loc[df_train[\"Zip Code\"].str.match(r'^0+$', na=False), \"Zip Code\"] = np.nan\n",
    "print(\"Replaced placeholder values with NaN in 'Zip Code'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814d5052-2454-4cdc-b534-ddd154621710",
   "metadata": {},
   "source": [
    "**Gender**: Replace unknown with NaN to be treated by imputer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "18a2976d-ad84-4769-b80f-4336cee21265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace unknown with NaN\n",
    "df_train['Gender'] = df_train['Gender'].replace(\"U\", np.nan)\n",
    "df_test['Gender'] = df_test['Gender'].replace(\"U\", np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f89701-ad24-4218-9f47-03657586cba8",
   "metadata": {},
   "source": [
    "## Feature removal\n",
    "Some features are useless as they're either not filled, have no variation or not present in the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f85c776c-8a1e-4457-9a9c-2f6cd08fc123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to display percentage distribution of values in a column if it exists\n",
    "def display_value_percentages(df, column_name):\n",
    "    if column_name in df.columns:\n",
    "        percentages = df[column_name].value_counts(normalize=True) * 100\n",
    "        print(f\"Percentage distribution in '{column_name}' - {df.name}:\")\n",
    "        print(percentages)\n",
    "        print(\"\\n\")\n",
    "    else:\n",
    "        print(f\"Column '{column_name}' does not exist in {df.name}.\\n\")\n",
    "\n",
    "# Assign names to the dataframes for display purposes\n",
    "df_train.name = 'df_train'\n",
    "df_test.name = 'df_test'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2bd51e-11ea-4c16-8e33-d0c7c4bd7115",
   "metadata": {},
   "source": [
    "**Feature OIICS Nature of Injury Description** is empty both in train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a7c80336-c36e-4c88-9678-52464fd1587f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage distribution in 'OIICS Nature of Injury Description' - df_train:\n",
      "Series([], Name: proportion, dtype: float64)\n",
      "\n",
      "\n",
      "Percentage distribution in 'OIICS Nature of Injury Description' - df_test:\n",
      "Series([], Name: proportion, dtype: float64)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check and display/drop \"OIICS Nature of Injury Description\" in df_train and df_test\n",
    "display_value_percentages(df_train, 'OIICS Nature of Injury Description')\n",
    "display_value_percentages(df_test, 'OIICS Nature of Injury Description')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bff5f1-0015-4af6-b26e-d69c2888b1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop(['OIICS Nature of Injury Description'], axis=1, errors='ignore')\n",
    "df_test = df_test.drop(['OIICS Nature of Injury Description'], axis=1, errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880ef839-1bca-4bae-8f3c-ac2f7094f44c",
   "metadata": {},
   "source": [
    "**Feature WCB Decision** is empty in test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "177e061d-e923-407b-8266-44647f47d7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage distribution in 'WCB Decision' - df_train:\n",
      "WCB Decision\n",
      "Not Work Related    100.0\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "\n",
      "Column 'WCB Decision' does not exist in df_test.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check and display/drop \"WCB Decision\" in df_train and df_test\n",
    "display_value_percentages(df_train, 'WCB Decision')\n",
    "display_value_percentages(df_test, 'WCB Decision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56499baf-5cf9-4bdb-a7ae-4ff43392e4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop(['WCB Decision'], axis=1, errors='ignore')\n",
    "df_test = df_test.drop(['WCB Decision'], axis=1, errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90232c2-b96b-4e2c-a01d-5cd98deeb92c",
   "metadata": {},
   "source": [
    "**Feature Agreement Reached** is empty in test dataset.\n",
    "\n",
    "- This could be a secondary target variable. As of 06.11.2024: We drop this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "129bba80-ef59-4506-a337-eb9cce7b137b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage distribution in 'Agreement Reached' - df_train:\n",
      "Agreement Reached\n",
      "0.0    95.335562\n",
      "1.0     4.664438\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "\n",
      "Column 'Agreement Reached' does not exist in df_test.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check and display/drop \"Agreement Reached\" in df_train and df_test\n",
    "display_value_percentages(df_train, 'Agreement Reached')\n",
    "display_value_percentages(df_test, 'Agreement Reached')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df734945-e37a-40d4-82f5-233d007d037a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop(['Agreement Reached'], axis=1, errors='ignore')\n",
    "df_test = df_test.drop(['Agreement Reached'], axis=1, errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543b0374-8cf6-4fa5-b405-d98a6561428b",
   "metadata": {},
   "source": [
    "## Row Removal\n",
    "Some rows can be dropped due to missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4630e602-3565-4f40-876b-0fb4f780417c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2. NON-COMP', '4. TEMPORARY', nan, '3. MED ONLY',\n",
       "       '5. PPD SCH LOSS', '6. PPD NSL', '1. CANCELLED', '8. DEATH',\n",
       "       '7. PTD'], dtype=object)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"Claim Injury Type\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6615c1fa-1bd4-4a36-a527-d0dc771e170b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove rows where the target variable is NaN\n",
    "df_train.dropna(axis = 0 , subset=[\"Claim Injury Type\"],inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d340b16a-6f19-4c94-94b4-cd9784577510",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d8a3cde3-06be-4663-935e-4f56d9234f78",
   "metadata": {},
   "source": [
    "## Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab922c60-6cad-4903-91cb-0a8896bac97c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b913cb33-22a5-4b5e-b47f-b9c8475769fc",
   "metadata": {},
   "source": [
    "## Imputing Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73bf526-9097-4a25-88aa-9f863f8803d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47323dc7-a434-4388-b97d-a1534672a563",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c350c5-fc54-4242-9030-9cb221e465eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82319abc-31e0-41fb-bbb6-f7da81f84616",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4e89a60b-f672-4547-9375-372b74c81e53",
   "metadata": {},
   "source": [
    "## Feature Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0496e4cc-9924-4cae-91ce-974a8cb83d67",
   "metadata": {},
   "source": [
    "**Accident date SPLIT**: Transform to four new features (day, month, year, weekday)\n",
    "\n",
    "- Why? E.g. Weekday vs weekend might impact decision as weekend is likely not work related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1efd09-fe2f-43e5-b844-4d0bf7a36262",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accident_time['Accident Year'] = df_acident_time['Accident Date'].dt.year\n",
    "df_accident_time['Accident Month'] = df_acident_time['Accident Date'].dt.month\n",
    "df_accident_time['Accident Day'] = df_acident_time['Accident Date'].dt.day\n",
    "df_accident_time['Accident DayOfWeek'] = df_acident_time['Accident Date'].dt.dayofweek"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a1481a-66ff-44a0-bd4c-eeffb2723eec",
   "metadata": {},
   "source": [
    "**All Dates**: Days passed since accident\n",
    "\n",
    "- Why? We assume this holds predictive power and is easier to interpret for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35f0532-693e-4e22-b892-2f14a831bbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_days_since_accident(df, accident_date_col='Accident Date', date_columns=None):\n",
    "    \"\"\"\n",
    "    Add new columns to the DataFrame representing days since the accident date for each specified date column.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The DataFrame containing the date columns.\n",
    "        accident_date_col (str): The column name for the accident date.\n",
    "        date_columns (list): List of date columns to calculate days since accident for. Accident date itself will be excluded.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with new 'Days Since Accident' columns added.\n",
    "    \"\"\"\n",
    "    if date_columns is None:\n",
    "        date_columns = []\n",
    "    \n",
    "    for col in date_columns:\n",
    "        if col != accident_date_col:\n",
    "            dsa_col = f\"{col} DSA\"\n",
    "            df[dsa_col] = (df[col] - df[accident_date_col]).dt.days\n",
    "            print(f\"Column '{dsa_col}' created to represent days since '{accident_date_col}'.\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600a2d00-94bb-4417-a9c6-1511a1c750ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = add_days_since_accident(df_train, accident_date_col='Accident Date', date_columns=date_columns)\n",
    "df_test = add_days_since_accident(df_test, accident_date_col='Accident Date', date_columns=date_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d03384-a5d1-4a60-a3c7-3f632a3e9829",
   "metadata": {},
   "source": [
    "**Age Category** - Split age into groups\n",
    "\n",
    "- Why? To give model a categorical feature for age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d386f58a-012b-4bfa-9407-9a2b90a51393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define age category mapping\n",
    "age_bins = [0, 19, 25, 40, 60, 120]  # Age ranges\n",
    "age_labels = ['Teen', 'Young Adult', 'Adult', 'Middle-Aged', 'Senior']  # Category labels\n",
    "age_column = 'Age At Injury'\n",
    "\n",
    "# Create 'Age At Injury Category' based on bins\n",
    "df_train['Age At Injury Category'] = pd.cut(df_train[age_column], bins=age_bins, labels=age_labels, right=False)\n",
    "df_test['Age At Injury Category'] = pd.cut(df_test[age_column], bins=age_bins, labels=age_labels, right=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e5e86c-c158-434c-b6fd-3ff601aea262",
   "metadata": {},
   "source": [
    "**Carrier Name** - Claim Category\n",
    "\n",
    "- To indicate if Carrier has a lot of claims, medium amount or low amount of them.\n",
    "- Why? Easier to interpret for the model than 2000 categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552a13ed-42dc-45d2-9717-a95e927d488c",
   "metadata": {},
   "source": [
    "# TODO move to explo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b78d8d7-b094-4522-b11b-2196c0edb2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of claims per carrier\n",
    "carrier_counts = df_train['Carrier Name'].value_counts()\n",
    "\n",
    "# Exclude \"State Insurance Fund\"\n",
    "carrier_counts = carrier_counts[carrier_counts.index != 'STATE INSURANCE FUND']\n",
    "\n",
    "# Plotting the boxplot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x=carrier_counts)\n",
    "plt.title('Distribution of Claim Counts per Carrier (Excluding State Insurance Fund)')\n",
    "plt.xlabel('Number of Claims')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c59c146-729d-473f-a9e4-5c9737eb4bdc",
   "metadata": {},
   "source": [
    "Decision:\n",
    "- Category HIGH for State Fund\n",
    "- Category MEDIUM for 5k to 50k claims\n",
    "- Category LOW for 5k and below claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f547483-86d7-4dae-bc9a-80f887d7da24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Calculate the claim counts per carrier\n",
    "carrier_counts = df_train['Carrier Name'].value_counts()\n",
    "\n",
    "# Step 2: Define a function to categorize each carrier based on its claim count\n",
    "def categorize_claims(count):\n",
    "    if count >= 50000:\n",
    "        return 'HIGH'\n",
    "    elif 5000 <= count < 50000:\n",
    "        return 'MEDIUM'\n",
    "    else:\n",
    "        return 'LOW'\n",
    "\n",
    "# Step 3: Apply the categorization to create a mapping dictionary\n",
    "carrier_category_map = carrier_counts.apply(categorize_claims)\n",
    "\n",
    "# Step 4: Map the `Carrier Name` in the original DataFrame to the new `Carrier Claim Category`\n",
    "df_train['Carrier Claim Category'] = df_train['Carrier Name'].map(carrier_category_map)\n",
    "\n",
    "# Display the first few rows to verify\n",
    "df_train[['Carrier Name', 'Carrier Claim Category']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505c2630-729c-44b3-b6f9-e09e5b6a5e2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c7001a-501a-4221-852c-7690039b4b54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec3e46d-7b5f-407b-b7ad-191338af7a34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
