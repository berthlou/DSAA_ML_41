{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff952f68-70e0-410d-869e-8657fcda3e99",
   "metadata": {},
   "source": [
    "###### Notes\n",
    "If enough time, make visualizations for the time variables, map visualizations for location variables and try to predict \"Agreement Reached\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e58895a-f32f-4b6f-a51b-8cee8144cee6",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "b1650a11-757b-4789-b76e-e8afa69602bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import chi2_contingency\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "b5516223-7631-42d7-bab5-a512d553cad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_memory = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34702d17-d593-4255-9374-391bca21dcfa",
   "metadata": {},
   "source": [
    "# Importing the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "c72a76ab-e0bf-48e0-b401-83b78f12e118",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gonca\\AppData\\Local\\Temp\\ipykernel_19768\\2463506257.py:1: DtypeWarning: Columns (29) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(\"C:\\\\Users\\\\gonca\\\\Downloads\\\\project_data\\\\train_data.csv\")\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"C:\\\\Users\\\\gonca\\\\Downloads\\\\project_data\\\\train_data.csv\")\n",
    "data = data.copy()\n",
    "data_test = pd.read_csv(\"C:\\\\Users\\\\gonca\\\\Downloads\\\\project_data\\\\test_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f8e7f5-eb7c-490f-99d9-756fd3f5f2da",
   "metadata": {},
   "source": [
    "# Exploratory analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53eee980-e2ab-4a06-acc7-c7e318fdc1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize our data and all columns\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fb027a-985a-4f8e-bda2-0fcc078c0a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the columns data types\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0288ef51-9914-489e-8535-9606ffcc1e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting all date variables to datatype64 so we can work with them\n",
    "data[\"Accident Date\"] = pd.to_datetime(data[\"Accident Date\"], \n",
    " format = \"%Y-%m-%d\", \n",
    " errors = \"coerce\")\n",
    "\n",
    "data[\"Assembly Date\"] = pd.to_datetime(data[\"Assembly Date\"], \n",
    " format = \"%Y-%m-%d\", \n",
    " errors = \"coerce\")\n",
    "\n",
    "data[\"C-2 Date\"] = pd.to_datetime(data[\"C-2 Date\"], \n",
    " format = \"%Y-%m-%d\", \n",
    " errors = \"coerce\")\n",
    "\n",
    "data[\"C-3 Date\"] = pd.to_datetime(data[\"C-3 Date\"], \n",
    " format = \"%Y-%m-%d\", \n",
    " errors = \"coerce\")\n",
    "\n",
    "data[\"First Hearing Date\"] = pd.to_datetime(data[\"First Hearing Date\"], \n",
    " format = \"%Y-%m-%d\", \n",
    " errors = \"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48199c1d-2a28-40e7-bef4-e9c40890c5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for incoherences in the dates\n",
    "print((data[\"Accident Date\"] > data[\"Assembly Date\"]).sum()) \n",
    "print((data[\"Accident Date\"] > data[\"C-2 Date\"]).sum())\n",
    "print((data[\"Accident Date\"] > data[\"C-3 Date\"]).sum())\n",
    "print((data[\"Accident Date\"] > data[\"First Hearing Date\"]).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1686b634-db2b-4b2f-a2b1-f6ac3b006902",
   "metadata": {},
   "source": [
    "There are several inconsitencies that we will have to remove in the next step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598b3a69-c193-4d4b-8997-ac8d3fe7157a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking statistics for our numerical features (except the codes but its still usefull to see their count)\n",
    "data.describe().round(2).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a70bea9-66de-4037-a4e0-5a5bb8881b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking statistics for our categorical features\n",
    "data.describe(include=[\"O\"]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f8c517-0717-4f8c-ba21-4e2abbbf979e",
   "metadata": {},
   "source": [
    "We can conclude that: <br>\n",
    "There are a lot of missing values in _C-3 Date_, _First Hearing Date_, _IME-4 Count_ and _OIICS Nature of Injury Description_. <br>\n",
    "There are no values for _OIICS Nature of Injury Description_. <br>\n",
    "_Birth Year_ has a minimum value of 0 which is obviously a missing value since no one as we know of lived for more than 122.5 years <br>\n",
    "There is also another that shouldn't have 0's as their minimum such as _Average Weekly Wage_  but we will be able to detect more of these anomalies in the visualization <br>\n",
    "We only have three binary variables, _Attorney/Representative_ , _COVID-19 Indicator_ and _Agreement Reached_ <br>\n",
    "We have a univarite variable that is _WCB Decision_ that only has the value Not Work Related\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ee0284-e516-455b-8975-8f51c0269482",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Checking the percentage of NA per variable in descending order\n",
    "\n",
    "print((data.isna().sum() / data.shape[0] *100).sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c130b61-a30b-4ec0-8e45-84a1e5646427",
   "metadata": {},
   "source": [
    "There are 4 variables with more than half of their values missing (as we already expected), and only 2 that don't have missing values <br>\n",
    "The rest of our data has around 5% missing values which we will have to deal with in the next step\n",
    "Also we have a lot of variables that have the exact same number of missing values which means they probably have missing values in the same rows but we will have to check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35ac8c3-1726-40ce-9e32-5e852bd8aae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking if the following variables have all their missing values in the same rows:\n",
    "data[data[\"Gender\"].isna()][[\"Gender\",\"Age at Injury\",\"District Name\",\"COVID-19 Indicator\",\"Medical Fee Region\",\"County of Injury\",\"Claim Injury Type\",\"Carrier Type\",\"Carrier Name\",\"Attorney/Representative\",\"Alternative Dispute Resolution\",\"Agreement Reached\",\"WCB Decision\",\"Number of Dependents\"]].info()\n",
    "data[data[\"WCIO Part Of Body Code\"].isna()][[\"WCIO Part Of Body Code\",\"WCIO Part Of Body Description\"]].info()\n",
    "data[data[\"WCIO Nature of Injury Code\"].isna()][[\"WCIO Nature of Injury Code\",\"WCIO Nature of Injury Description\"]].info()\n",
    "data[data[\"WCIO Cause of Injury Code\"].isna()][[\"WCIO Cause of Injury Code\",\"WCIO Cause of Injury Description\"]].info()\n",
    "data[data[\"Industry Code\"].isna()][[\"Industry Code\",\"Industry Code Description\"]].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5edbffa-5c4f-4872-a2ab-1879f3c76cad",
   "metadata": {},
   "source": [
    "All the missing values that are in variable codes are in the respective variable descriptions too, showing no inconsistencies <br>\n",
    "What is interesting is that there are 14 variables that show missing values in all the same rows and they aren't dependent of each other"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b980c3-7817-41c4-8702-501570add2c4",
   "metadata": {},
   "source": [
    "### Visualizing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9665cff4-1ec5-4d6d-9bf6-40e6c4ffa312",
   "metadata": {},
   "source": [
    "###### Making visualization functions for different plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b4d64b-1220-4971-8f82-d49571f2d4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bar(col, degrees = 0):\n",
    "    \n",
    "    column = data[col].value_counts()\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x=column.index.astype(str), y=column.values)\n",
    "    plt.xlabel(f\"{col}\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.xticks(rotation=degrees)  \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04708526-a9e7-4b75-b27e-7eff141b21a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist(col, rotate = False):\n",
    "    column = data[col].value_counts()\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(data[col], bins=30, kde = True)\n",
    "    plt.xlabel(f\"{col}\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    if rotate:\n",
    "        plt.xticks(rotation=45)  \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5032b31-376d-42f7-a678-e5498a519bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_box(col):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.boxplot(x=data[col])\n",
    "    plt.xlabel(f\"{col}\")\n",
    "    plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e66c6a-1989-4a72-be72-93c10ab0cf56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pie(col):\n",
    "    value_counts = data[col].value_counts()\n",
    "    total = value_counts.sum()\n",
    "    percentages = (value_counts / total) * 100\n",
    "\n",
    "    above_threshold = percentages[percentages >= 2]\n",
    "    below_threshold = percentages[percentages < 2]\n",
    "\n",
    "    if len(below_threshold) > 0:\n",
    "        other_percentage = below_threshold.sum()\n",
    "        above_threshold['Others'] = other_percentage\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    above_threshold.plot.pie(\n",
    "        autopct='%1.1f%%', \n",
    "        startangle=90, \n",
    "        labels=above_threshold.index\n",
    "    )\n",
    "    plt.ylabel(\"\")\n",
    "    plt.xlabel(f\"{col}\")\n",
    "    plt.legend(title=\"Legend\", loc='upper left')  \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53ca5ea-56ca-47ce-9902-38a34a423a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_heatmap(numerical):\n",
    "    plt.figure(figsize=(12,10))\n",
    "    sns.heatmap(data = data[numerical].corr(method = 'spearman'), annot = True, cmap = \"coolwarm\", fmt='.1')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c1c735-15f9-497f-a857-7edea1043779",
   "metadata": {},
   "source": [
    "###### Saving the columns with numerical features, categorical features and the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9214b6b-3831-49df-abc2-657c89ab3e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = ['Accident Date', 'Age at Injury', 'Assembly Date',\n",
    "       'Average Weekly Wage', 'Birth Year', 'C-2 Date', 'C-3 Date',\n",
    "        'First Hearing Date', 'IME-4 Count', 'Number of Dependents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291d07d9-9e22-4578-9b98-e4ddb520510a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = ['Alternative Dispute Resolution', 'Attorney/Representative',\n",
    "       'Carrier Name', 'Carrier Type','County of Injury',\n",
    "       'COVID-19 Indicator', 'District Name', 'Gender','Industry Code',\n",
    "       'Industry Code Description', 'Medical Fee Region','WCIO Cause of Injury Code',\n",
    "       'WCIO Cause of Injury Description', 'WCIO Nature of Injury Code', \n",
    "       'WCIO Nature of Injury Description', 'WCIO Part Of Body Code', 'Agreement Reached',\n",
    "       'WCIO Part Of Body Description', 'Zip Code', 'WCB Decision']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a573bb66-0f54-4f85-8719-582f579b1700",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = [\"Claim Injury Type\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db012c44-21cd-484b-84f0-ea3932d4df42",
   "metadata": {},
   "source": [
    "###### Finally seeing plots of our data minus date variables and categorical ones with lots of variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d2b810-f453-4c75-920e-d95ec2e1c5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist(\"Age at Injury\")\n",
    "plot_bar(\"Alternative Dispute Resolution\")\n",
    "plot_pie(\"Attorney/Representative\")\n",
    "plot_box(\"Average Weekly Wage\")\n",
    "plot_hist(\"Birth Year\")\n",
    "plot_pie(\"Carrier Type\")\n",
    "plot_bar(\"Claim Injury Type\", 45)\n",
    "plot_pie(\"COVID-19 Indicator\")\n",
    "plot_bar(\"District Name\")\n",
    "plot_bar(\"Gender\")\n",
    "plot_bar(\"IME-4 Count\", 45)\n",
    "plot_box(\"IME-4 Count\")\n",
    "plot_pie(\"Medical Fee Region\")\n",
    "plot_pie(\"Agreement Reached\")\n",
    "plot_pie(\"Number of Dependents\")\n",
    "plot_heatmap(num_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55cbf97-9058-49d4-9777-a5ee8c639b37",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "We can see in Age at _Injury_ there are a lot of 0 that are impossible but there are also a few values below 18 and above 80 that should also be impossible. <br>\n",
    "Almost all values in  _Alternative Dispute Resolution_ are N and there are practically no U's (5 observations) <br>\n",
    "_Average Weekly Wage_ has some very extreme outliers <br>\n",
    "_Birth Year_ suffers from the same problem as Age as expected and has a lot of 0's <br>\n",
    "Half of the possible values of _Carrier Type_ have very few observation and are either unkown or special funds <br>\n",
    "_Gender_ has very rare categories such as U and X that only has 46 observations <br>\n",
    "_IME-4_ seems to have a Half Normal Distribution and has an outlier at 73.0 <br>\n",
    "_Number of Dependents_ weirdly has around the same number of variables for each amount between 0 and 6 which doesn't mimic the population <br>\n",
    "The numerical variables that are highly correlated with each other are Age at Injury and Birth Year as expected, Assembly Date and Aciddent Date, Accident Date and C-2 Date, C-2 Date and Assembly date. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d399c7ac-8174-462e-aa78-c95ab64fdde3",
   "metadata": {},
   "source": [
    "# Data Pre-processment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e14d6bb-19be-40b5-a089-2b7bbb099d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining Claim identifier as the index\n",
    "data.set_index('Claim Identifier', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1f29ce-b118-4957-81ef-3fc5d90ea686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping variables that are definitely useless from our dataset\n",
    "# The first variable has 100% missing values and the second only contains one type of value,\n",
    "# meaning it doesn't provide any useful information\n",
    "data = data.drop([\"OIICS Nature of Injury Description\", \"WCB Decision\"], axis=1)\n",
    "cat_features.remove('WCB Decision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae509598-8dab-47df-af0f-d80ec0293bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping \"Agreement Reached\" because it is not on the validation dataset\n",
    "#Later we can try to predict this column and then predict the target but for now lets drop ot\n",
    "data = data.drop(['Agreement Reached'], axis=1)\n",
    "cat_features.remove(\"Agreement Reached\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d44e33-c89d-443a-87fc-0f3e6e055ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove rows where the target variable is NaN\n",
    "data.dropna(axis = 0 , subset=[\"Claim Injury Type\"],inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7a0b3f-c165-4e89-82f4-0badf76b841f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing duplicates\n",
    "data.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3452fac-fed7-479f-b1dc-265e13f057db",
   "metadata": {},
   "source": [
    "### Spliting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0da8ea-afe0-4ad1-b291-96b89dd5858f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop([\"Claim Injury Type\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9026cf-b11e-46a2-9df3-903e7d258f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[\"Claim Injury Type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c38fea-4526-4df3-aaba-09768e6e0e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_validation,y_train, y_validation = train_test_split(X,y,\n",
    "                                                               train_size = 0.75, \n",
    "                                                               shuffle = True, \n",
    "                                                               stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1619dd75",
   "metadata": {},
   "source": [
    "### Removing inconsistencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e250f28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove the rows where the age of the injury is greater than 75 or between 1 and 17\n",
    "X_train = X_train[(data['Age at Injury'] > 75) | ((data[\"Age at Injury\"] <18) & (data[\"Age at Injury\"] > 0))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23184c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove Changed Dates \n",
    "def is_date_order_correct(row):\n",
    "    accident_date = row[\"Accident Date\"]\n",
    "    assembly_date = row[\"Assembly Date\"]\n",
    "    first_hearing_date = row[\"First Hearing Date\"]\n",
    "    \n",
    "    if pd.notna(accident_date) and pd.notna(assembly_date):\n",
    "        if accident_date > assembly_date:\n",
    "            return False\n",
    "    \n",
    "    if pd.notna(assembly_date) and pd.notna(first_hearing_date):\n",
    "        if assembly_date > first_hearing_date:\n",
    "            return False\n",
    "\n",
    "    return True\n",
    "\n",
    "X_train = X_train[X_train.apply(is_date_order_correct, axis=1)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e853a495",
   "metadata": {},
   "source": [
    "Check for inconsistencies between code columns and their description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6926bfa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For check  any inconsistencies between codes and descriptions\n",
    "def inconsistent_pairs(data, code, descripion):\n",
    "    duplos = data.groupby(code)[descripion].nunique()\n",
    "\n",
    "    inconsistent_codes = duplos[duplos > 1].index\n",
    "    inconsistent_rows = data[data[code].isin(inconsistent_codes)]\n",
    "\n",
    "    return inconsistent_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21a67a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chamar a função para cada par de colunas\n",
    "print(inconsistent_pairs(data, 'Industry Code', 'Industry Code Description'))\n",
    "print(inconsistent_pairs(data, 'WCIO Cause of Injury Code', 'WCIO Cause of Injury Description'))\n",
    "print(inconsistent_pairs(data, 'WCIO Nature of Injury Code', 'WCIO Nature of Injury Description'))\n",
    "print(inconsistent_pairs(data, 'WCIO Part Of Body Code', 'WCIO Part Of Body Description'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc5dd21-3733-4e89-9130-96ec78304833",
   "metadata": {},
   "source": [
    "### Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771e9a40",
   "metadata": {},
   "source": [
    "Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f768d04b-b070-4a9f-a65f-9594942ff2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the missing values in the categorical variables\n",
    "\n",
    "#We fill missing values in categorical data with missing because if it is not missing at random, it might hold predictive power\n",
    "existing_cat_features = [col for col in cat_features if col in data.columns]\n",
    "X_train[existing_cat_features] = X_train[existing_cat_features].fillna(\"Missing\")\n",
    "X_validation[existing_cat_features] = X_validation[existing_cat_features].fillna(\"Missing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40a2903",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = ['Accident Date', 'Age at Injury', 'Assembly Date','Average Weekly Wage', 'Birth Year','C-2 Date', 'C-3 Date', 'First Hearing Date', 'IME-4 Count', 'Number of Dependents']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1218beb",
   "metadata": {},
   "source": [
    "Numeric Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e471ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree to input numerical missing values \n",
    "def impute_with_decision_tree(data, target_column):\n",
    "    # Separate our data in the missing and non missing values\n",
    "    available_data = X_train[X_train[target_column].notna()]\n",
    "    missing_data = X_train[X_train[target_column].isna()]\n",
    "\n",
    "    # Make sure we have data to train or input\n",
    "    if len(available_data) == 0 or len(missing_data) == 0:\n",
    "        return\n",
    "    \n",
    "    # making sure we are using only numerical data\n",
    "    available_data_numeric = available_data.select_dtypes(include=['float64', 'int64', 'datetime64[ns]']).copy()\n",
    "    missing_data_numeric = missing_data.select_dtypes(include=['float64', 'int64', 'datetime64[ns]']).copy()\n",
    "\n",
    "    # Converting date variables into integers\n",
    "    available_data_numeric = available_data_numeric.apply(lambda x: x.astype('int64') // 10**9 if x.dtype == 'datetime64[ns]' else x)\n",
    "    missing_data_numeric = missing_data_numeric.apply(lambda x: x.astype('int64') // 10**9 if x.dtype == 'datetime64[ns]' else x)\n",
    "\n",
    "    # Making sure again if we still have data after filtering our previous data\n",
    "    if available_data_numeric.empty or missing_data_numeric.empty:\n",
    "        return\n",
    "\n",
    "    # Separating the target column from the training ones\n",
    "    X_available = available_data_numeric.drop(columns=target_column)\n",
    "    y_available = available_data_numeric[target_column]\n",
    "\n",
    "    # Training and fiting the model\n",
    "    model = DecisionTreeRegressor()\n",
    "    model.fit(X_available, y_available)\n",
    "\n",
    "    # Predicting the missing variables\n",
    "    X_missing = missing_data_numeric.drop(columns=target_column)\n",
    "    predicted_values = model.predict(X_missing)\n",
    "\n",
    "    # If the column we are feeling is a date variable we convert it back to its type\n",
    "    if pd.api.types.is_datetime64_ns_dtype(data[target_column]):\n",
    "        predicted_values = pd.to_datetime(predicted_values, unit='s')  \n",
    "\n",
    "    # Changing themissing values to the predicted ones\n",
    "    data.loc[data[target_column].isna(), target_column] = predicted_values\n",
    "\n",
    "# Filling the missing values\n",
    "for column in num_features:\n",
    "    impute_with_decision_tree(X_train, column)\n",
    "    impute_with_decision_tree(X_validation, column)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
